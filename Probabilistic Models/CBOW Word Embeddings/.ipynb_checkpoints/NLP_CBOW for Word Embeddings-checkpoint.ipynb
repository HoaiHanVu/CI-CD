{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06108a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vuhan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import linalg\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da6de9",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d07a01",
   "metadata": {},
   "source": [
    "- Clean and tokenize the corpus.\n",
    "\n",
    "- Extract the pairs of context words and center word that will make up the training data set for the CBOW model. The context words are the features that will be fed into the model, and the center words are the target values that the model will learn to predict.\n",
    "\n",
    "- Create simple vector representations of the context words (features) and center words (targets) that can be used by the neural network of the CBOW model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec442ade",
   "metadata": {},
   "source": [
    "## 1.1 Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724503a",
   "metadata": {},
   "source": [
    "First, replace all interrupting punctuation signs — such as commas and exclamation marks — with periods.\n",
    "\n",
    "Next, use NLTK's tokenization engine to split the corpus into individual tokens.\n",
    "\n",
    "Finally, get rid of numbers and punctuation other than periods, and convert all the remaining tokens to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84e3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    data = re.sub(r'[,!?;-]+', '.', corpus)\n",
    "    data = nltk.word_tokenize(data)\n",
    "    data = [char.lower() for char in data\n",
    "           if char.isalpha()\n",
    "           or char == '.'\n",
    "           or emoji.get_emoji_regexp().search(char)\n",
    "           ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f91efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'happy',\n",
       " 'because',\n",
       " 'i',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'continuous',\n",
       " 'bags',\n",
       " 'of',\n",
       " 'word',\n",
       " 'for',\n",
       " 'words',\n",
       " 'embeddings',\n",
       " '❤️',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'I am happy because I am learning continuous bags of word for words embeddings ❤️!!!'\n",
    "\n",
    "words = tokenize(corpus)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8c202",
   "metadata": {},
   "source": [
    "## 1.2 Slicing window of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bd587",
   "metadata": {},
   "source": [
    "Now that we have transformed the corpus into a list of clean tokens, we can slide a window of words across this list. For each window we can extract a center word and the context words.\n",
    "\n",
    "The first argument of this function is a list of words (or tokens). The second argument, `C`, is the context half-size. Recall that for a given center word, the context words are made of `C` words to the left and `C` words to the right of the center word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6daea7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(words, C):\n",
    "    i = C\n",
    "    while i < len(words) - C:\n",
    "        center_word = words[i]\n",
    "        context_words = words[i-C:i] + words[i+1:i+C+1]\n",
    "        yield context_words, center_word\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c1f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'happy'] am\n",
      "['am', 'because'] happy\n",
      "['happy', 'i'] because\n",
      "['because', 'am'] i\n",
      "['i', 'learning'] am\n",
      "['am', 'continuous'] learning\n",
      "['learning', 'bags'] continuous\n",
      "['continuous', 'of'] bags\n",
      "['bags', 'word'] of\n",
      "['of', 'for'] word\n",
      "['word', 'words'] for\n",
      "['for', 'embeddings'] words\n",
      "['words', '❤️'] embeddings\n",
      "['embeddings', '.'] ❤️\n"
     ]
    }
   ],
   "source": [
    "for x, y in get_windows(tokenize(corpus), 1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488948a",
   "metadata": {},
   "source": [
    "## 1.3 Transforming word into vectors for training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e41ae",
   "metadata": {},
   "source": [
    "### 1.3.1 Mapping words to indices and indices to words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dc7da",
   "metadata": {},
   "source": [
    "The center words will be represented as one-hot vectors, and the vectors that represent context words are also based on one-hot vectors.\n",
    "\n",
    "To create one-hot word vectors, we can start by mapping each unique word to a unique integer (or index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d95f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: the data want to pull from\n",
    "    Output:\n",
    "        word2idx: returns dictionary mapping the word to its index\n",
    "        idx2word: returns dictionary mapping the index to its word\n",
    "    \"\"\"\n",
    "    words = sorted(list(set(data)))\n",
    "    n = len(words)\n",
    "    idx = 0\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for k in words:\n",
    "        word2idx[k] = idx\n",
    "        idx2word[idx] = k\n",
    "        idx += 1\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d6835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'am': 1, 'bags': 2, 'because': 3, 'continuous': 4, 'embeddings': 5, 'for': 6, 'happy': 7, 'i': 8, 'learning': 9, 'of': 10, 'word': 11, 'words': 12, '❤️': 13}\n",
      "\n",
      "{0: '.', 1: 'am', 2: 'bags', 3: 'because', 4: 'continuous', 5: 'embeddings', 6: 'for', 7: 'happy', 8: 'i', 9: 'learning', 10: 'of', 11: 'word', 12: 'words', 13: '❤️'}\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = get_dict(words)\n",
    "\n",
    "print(word2idx)\n",
    "print()\n",
    "print(idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4b9e1",
   "metadata": {},
   "source": [
    "### 1.3.2 Getting one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83648521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_one_hot_vector(word, word2idx, V):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the letter of corpus want to transform into one hot vector\n",
    "        word2idx: dictionary with key is word and value is index of word in string\n",
    "        V: size of vocabulary\n",
    "    Output:\n",
    "        one_hot_vector: a vector one hot of word\n",
    "    \"\"\"\n",
    "    one_hot_vector = np.zeros(V)\n",
    "    one_hot_vector[word2idx[word]] = 1\n",
    "    \n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0518a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_one_hot_vector('word', word2idx, len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b72619",
   "metadata": {},
   "source": [
    "### 1.3.3 Getting context words vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b9727",
   "metadata": {},
   "source": [
    "To create the vectors that represent context words, we will calculate the average of the one-hot vectors representing the individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bcaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_words_to_vector(context_words, word2idx, V):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        context_words: list of context words\n",
    "        word2idx: dictionary with key is word and value is index of word in string\n",
    "        V: size of vocabulary\n",
    "    Output:\n",
    "        context_words_vector: vectors of all context words\n",
    "    \"\"\"\n",
    "    context_words_vectors = [word_to_one_hot_vector(w, word2idx, V) for w in context_words]\n",
    "    context_words_vectors = np.mean(context_words_vectors, axis=0)\n",
    "    \n",
    "    return context_words_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe76e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "       0. ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_words_to_vector(['am', 'continuous'], word2idx, len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685f326",
   "metadata": {},
   "source": [
    "## 1.4 Building the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1e0f9",
   "metadata": {},
   "source": [
    "To do this we need to use the sliding window function (`get_windows`) to extract the context words and center words, and we then convert these sets of words into a basic vector representation using `word_to_one_hot_vector` and `context_words_to_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf8c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_example(words, C, word2idx, V):\n",
    "    for context_words, center_word in get_windows(words, C):\n",
    "        yield context_words_to_vector(context_words, word2idx, V),\\\n",
    "              word_to_one_hot_vector(center_word, word2idx, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9881506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context words vector:  [0.   0.25 0.   0.25 0.   0.   0.   0.   0.5  0.   0.   0.   0.   0.  ]\n",
      "Center word vector:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Context words vector:  [0.   0.5  0.   0.   0.   0.   0.   0.25 0.25 0.   0.   0.   0.   0.  ]\n",
      "Center word vector:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Context words vector:  [0.   0.25 0.   0.25 0.   0.   0.   0.25 0.   0.25 0.   0.   0.   0.  ]\n",
      "Center word vector:  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Context words vector:  [0.   0.   0.   0.25 0.25 0.   0.   0.   0.25 0.25 0.   0.   0.   0.  ]\n",
      "Center word vector:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V = len(word2idx)\n",
    "for context_words_vector, center_word_vector in get_training_example(words[:8], 2, word2idx, V):\n",
    "    print(f'Context words vector:  {context_words_vector}')\n",
    "    print(f'Center word vector:  {center_word_vector}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6498a5",
   "metadata": {},
   "source": [
    "## 1.5 Deviding training set into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32abec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(words, word2idx):\n",
    "    idx = []\n",
    "    for word in words:\n",
    "        idx = idx + [word2idx[word]]\n",
    "    return idx\n",
    "\n",
    "def pack_idx_with_frequency(context_words, word2idx):\n",
    "    freq_dict = defaultdict(int)\n",
    "    for word in context_words:\n",
    "        freq_dict[word] += 1\n",
    "    idxs = get_idx(context_words, word2idx)\n",
    "    packed = []\n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        freq = freq_dict[context_words[i]]\n",
    "        packed.append((idx, freq))\n",
    "    return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ba718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, word2idx, V, C):\n",
    "    i = C\n",
    "    while True:\n",
    "        y = np.zeros(V)\n",
    "        x = np.zeros(V)\n",
    "        center_word = data[i]\n",
    "        y[word2idx[center_word]] = 1\n",
    "        context_words = data[(i - C) : i] + data[(i + 1) : (i + C + 1)]\n",
    "        num_ctx_words = len(context_words)\n",
    "        for idx, freq in pack_idx_with_frequency(context_words, word2idx):\n",
    "            x[idx] = freq / num_ctx_words\n",
    "        yield x, y\n",
    "        i += 1\n",
    "        if i >= len(data) - C:\n",
    "#             print(\"i is being set to\", C)\n",
    "            i = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d3414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, word2idx, V, C, batch_size):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for x, y in get_vectors(data, word2idx, V, C):\n",
    "        while len(batch_x) < batch_size:\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        else:\n",
    "            yield np.array(batch_x).T, np.array(batch_y).T\n",
    "            batch_x = []\n",
    "            batch_y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a99e1c",
   "metadata": {},
   "source": [
    "# 2. The shallow neurals network for continuous bag-of-words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e934b92",
   "metadata": {},
   "source": [
    "## 2.1 Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d3d63",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272fe0",
   "metadata": {},
   "source": [
    "ReLU is used to calculate the values of the hidden layer, in the following formulas:\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{z_1} &= \\mathbf{W_1}\\mathbf{x} + \\mathbf{b_1}  \\ \\\\\n",
    " \\mathbf{h} &= \\mathrm{ReLU}(\\mathbf{z_1})  \\ \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b7d7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98b8f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25459881],\n",
       "       [ 4.50714306],\n",
       "       [ 2.31993942],\n",
       "       [ 0.98658484],\n",
       "       [-3.4398136 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "z1 = 10 * np.random.rand(5, 1) - 5\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eff672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [4.50714306],\n",
       "       [2.31993942],\n",
       "       [0.98658484],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b6cdb",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95472c61",
   "metadata": {},
   "source": [
    "The second activation function that we need is softmax. This function is used to calculate the values of the output layer of the neural network, using the following formulas:\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{z_2} &= \\mathbf{W_2}\\mathbf{h} + \\mathbf{b_2}   \\\\\\\n",
    " \\mathbf{\\hat y} &= \\mathrm{softmax}(\\mathbf{z_2})   \\\\\\\n",
    "\\end{align}\n",
    "\n",
    "To calculate softmax of a vector $\\mathbf{z}$, the $i$-th component of the resulting vector is given by:\n",
    "\n",
    "$$ \\textrm{softmax}(\\textbf{z})_i = \\frac{e^{z_i} }{\\sum\\limits_{j=1}^{V} e^{z_j} }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24f41810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    yhat = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4bbe7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = np.array([9, 8, 11, 10, 8.5])\n",
    "\n",
    "softmax(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "603215ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56ebc",
   "metadata": {},
   "source": [
    "## 2.2 Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be3b2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y, yhat, batch_size):\n",
    "    loss = np.sum(np.multiply(np.log(yhat), y))\n",
    "    \n",
    "    cost = -1/batch_size * loss\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39ba42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = softmax(relu(z1))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "537ab803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.11385871598675"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(z1, y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424beed",
   "metadata": {},
   "source": [
    "## 2.3 Foward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eae12",
   "metadata": {},
   "source": [
    "### 2.3.1 Initialization of the weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0734c",
   "metadata": {},
   "source": [
    "- The first matrix ($W_1$) is of dimension $N \\times V$, where $V$ is the number of words in vocabulary and $N$ is the dimension of word vector.\n",
    "- The second matrix ($W_2$) is of dimension $V \\times N$. \n",
    "- Vector $b_1$ has dimensions $N\\times 1$\n",
    "- Vector $b_2$ has dimensions  $V\\times 1$. \n",
    "- $b_1$ and $b_2$ are the bias vectors of the linear layers from matrices $W_1$ and $W_2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7232f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(word2idx)\n",
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cb15452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(N, V, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    W1 = np.random.rand(N, V)\n",
    "    W2 = np.random.rand(V, N)\n",
    "    b1 = np.random.rand(N, 1)\n",
    "    b2 = np.random.rand(V, 1)\n",
    "    \n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a9b42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, W1, W2, b1, b2):\n",
    "    h = np.dot(W1, x) + b1\n",
    "    h = relu(h)\n",
    "    z = np.dot(W2, h) + b2\n",
    "    \n",
    "    return z, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "880d653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exp = get_training_example(words, 2, word2idx, V)\n",
    "\n",
    "x_arr, y_arr = next(training_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ff9612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X array: [0.   0.25 0.   0.25 0.   0.   0.   0.   0.5  0.   0.   0.   0.   0.  ]\n",
      "Y array [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('X array:', x_arr)\n",
    "print('Y array', y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f168d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.  ],\n",
       "       [0.25],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.5 ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ],\n",
       "       [0.  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_arr.copy().reshape((V, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d0a6eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_arr.copy().reshape((V, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3681d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, W2, b1, b2 = initialize_model(N, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cec6034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7422567 ]\n",
      " [1.96109371]\n",
      " [2.60634493]\n",
      " [1.72877741]\n",
      " [1.06192682]\n",
      " [1.7615788 ]\n",
      " [1.41772227]\n",
      " [1.89609992]\n",
      " [2.25082177]\n",
      " [1.86064522]\n",
      " [1.93908927]\n",
      " [0.82876426]\n",
      " [0.99547822]\n",
      " [0.99632302]]\n"
     ]
    }
   ],
   "source": [
    "z, h = forward_prop(x, W1, W2, b1, b2)\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd21efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72228922],\n",
       "       [1.23243296],\n",
       "       [0.4653305 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b51e7879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.51162236970795"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(y, softmax(z), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40964c4b",
   "metadata": {},
   "source": [
    "## 2.4 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9813e6a",
   "metadata": {},
   "source": [
    "The formulas will implement for backpropagation are the following.\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right )\\mathbf{x}^\\top \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_2}} &= (\\mathbf{\\hat{y}} - \\mathbf{y})\\mathbf{h^\\top} \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right ) \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_2}} &= \\mathbf{\\hat{y}} - \\mathbf{y} \\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bd50e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
    "    \n",
    "    grad_W1 = 1/batch_size * np.dot(relu(np.dot(W2.T, yhat - y)), x.T)\n",
    "    grad_W2 = 1/batch_size * np.dot(yhat - y, h.T)\n",
    "    grad_b1 = 1/batch_size * np.dot(relu(np.dot(W2.T, yhat -y)), np.ones((batch_size, 1)))\n",
    "    grad_b2 = 1/batch_size * np.dot(yhat - y, np.ones((batch_size, 1)))\n",
    "    \n",
    "    return grad_W1, grad_W2, grad_b1, grad_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58f1743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = softmax(z)\n",
    "\n",
    "grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11cffb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 14\n",
      "Shape of W1: (3, 14)\n",
      "Shape of W2: (14, 3)\n",
      "Shape of b1: (3, 1)\n",
      "Shape of b2: (14, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary: {}'.format(V))\n",
    "print('Shape of W1: {}'.format(grad_W1.shape))\n",
    "print('Shape of W2: {}'.format(grad_W2.shape))\n",
    "print('Shape of b1: {}'.format(grad_b1.shape))\n",
    "print('Shape of b2: {}'.format(grad_b2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b177c80",
   "metadata": {},
   "source": [
    "## 2.5 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbad56",
   "metadata": {},
   "source": [
    "During the gradient descent phase, we will update the weights and biases by subtracting $\\alpha$ times the gradient from the original matrices and vectors, using the following formulas.\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{W_1} &:= \\mathbf{W_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_1}} \\\\\\\n",
    " \\mathbf{W_2} &:= \\mathbf{W_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_2}} \\\\\\\n",
    " \\mathbf{b_1} &:= \\mathbf{b_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_1}} \\\\\\\n",
    " \\mathbf{b_2} &:= \\mathbf{b_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_2}} \\\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40ecc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(data, word2idx, N, V, num_iters, alpha, batch_sizes,\n",
    "                     initialize_model=initialize_model, get_batches=get_batches, forward_prop=forward_prop,\n",
    "                     softmax=softmax, compute_cost=compute_cost, back_prop=back_prop, random_seed=42):\n",
    "    '''\n",
    "    \n",
    "      Inputs: \n",
    "        data:      text/list of words\n",
    "        word2idx:  words to Indices\n",
    "        N:         dimension of hidden vector  \n",
    "        V:         dimension of vocabulary \n",
    "        num_iters: number of iterations  \n",
    "        random_seed: random seed to initialize the model's matrices and vectors\n",
    "        initialize_model: your implementation of the function to initialize the model\n",
    "        get_batches: function to get the data in batches\n",
    "        forward_prop: your implementation of the function to perform forward propagation\n",
    "        softmax: your implementation of the softmax function\n",
    "        compute_cost: cost function (Cross entropy)\n",
    "        back_prop: your implementation of the function to perform backward propagation\n",
    "     Outputs: \n",
    "        W1, W2, b1, b2:  updated matrices and biases after num_iters iterations\n",
    "\n",
    "    '''\n",
    "    W1, W2, b1, b2 = initialize_model(N, V, random_seed=random_seed)\n",
    "    batch_size = batch_sizes\n",
    "    \n",
    "    iters = 0\n",
    "    C = 2\n",
    "    \n",
    "    for x, y in get_batches(data, word2idx, V, C, batch_size):\n",
    "        z, h = forward_prop(x, W1, W2, b1, b2)\n",
    "        \n",
    "        yhat = softmax(z)\n",
    "        \n",
    "        cost = compute_cost(y, yhat, batch_size)\n",
    "        if (iters) % 10 == 0 and iters != 0:\n",
    "            print('Iters: {} cost: {:.5f}'.format(iters, cost))\n",
    "        \n",
    "        grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size)\n",
    "        \n",
    "        W1 = W1 - alpha * grad_W1\n",
    "        W2 = W2 - alpha * grad_W2\n",
    "        b1 = b1 - alpha * grad_b1\n",
    "        b2 = b2 - alpha * grad_b2\n",
    "        \n",
    "        iters += 1\n",
    "        if iters == num_iters:\n",
    "            break\n",
    "        if iters % 100 == 0:\n",
    "            alpha *= 0.66\n",
    "            \n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8e97e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters: 10 cost: 3.74320\n",
      "Iters: 20 cost: 3.42169\n",
      "Iters: 30 cost: 1.82111\n",
      "Iters: 40 cost: 2.50387\n",
      "Iters: 50 cost: 2.15783\n",
      "Iters: 60 cost: 2.46408\n",
      "Iters: 70 cost: 3.61920\n",
      "Iters: 80 cost: 3.33955\n",
      "Iters: 90 cost: 1.93015\n",
      "Iters: 100 cost: 2.50468\n",
      "Iters: 110 cost: 2.16987\n",
      "Iters: 120 cost: 2.42711\n",
      "Iters: 130 cost: 3.52821\n",
      "Iters: 140 cost: 3.28519\n",
      "Iters: 150 cost: 1.99561\n",
      "Iters: 160 cost: 2.50679\n",
      "Iters: 170 cost: 2.18157\n",
      "Iters: 180 cost: 2.40578\n",
      "Iters: 190 cost: 3.46684\n",
      "Iters: 200 cost: 3.24680\n",
      "Iters: 210 cost: 2.04454\n",
      "Iters: 220 cost: 2.50731\n",
      "Iters: 230 cost: 2.19004\n",
      "Iters: 240 cost: 2.38977\n",
      "Iters: 250 cost: 3.42597\n",
      "Iters: 260 cost: 3.22409\n",
      "Iters: 270 cost: 2.07781\n",
      "Iters: 280 cost: 2.50949\n",
      "Iters: 290 cost: 2.19755\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "V = len(word2idx)\n",
    "num_iters = 300\n",
    "alpha = 0.005\n",
    "batch_sizes = 1\n",
    "\n",
    "W1, W2, b1, b2 = gradient_descent(words, word2idx, N, V, num_iters, alpha, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635c12f",
   "metadata": {},
   "source": [
    "# 3. Extracting & Visualizing word embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651f489",
   "metadata": {},
   "source": [
    "### Option 1: extract embedding vectors from $\\mathbf{W_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e009cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79487258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35823699,  0.81111797,  0.62204948,  0.55474604,  0.093614  ,\n",
       "         0.14006133,  0.02751992,  0.86617615,  0.45088549,  0.67479332,\n",
       "        -0.04288852,  0.95397666,  0.78594575,  0.19603598],\n",
       "       [ 0.1469974 ,  0.12717735,  0.20916759,  0.47494509,  0.38213368,\n",
       "         0.25454733,  0.52801501,  0.13949386,  0.24233331,  0.26032334,\n",
       "         0.33447635,  0.74849415,  0.09947974,  0.46924404],\n",
       "       [ 0.59241457, -0.17612817,  0.53929132,  0.07106464,  0.01452948,\n",
       "         0.90597545,  0.87223225,  0.71470175,  0.13500447,  0.03893893,\n",
       "         0.66646918,  0.34672029,  0.12200581,  0.45229924]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99a362",
   "metadata": {},
   "source": [
    "The first column, which is a 3-element vector, is the embedding vector of the first word of your vocabulary. The second column is the word embedding vector for the second word, and so on.\n",
    "\n",
    "The first, second, etc. words are ordered as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c071d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:  [0.35823699 0.1469974  0.59241457]\n",
      "am:  [ 0.81111797  0.12717735 -0.17612817]\n",
      "bags:  [0.62204948 0.20916759 0.53929132]\n",
      "because:  [0.55474604 0.47494509 0.07106464]\n",
      "continuous:  [0.093614   0.38213368 0.01452948]\n",
      "embeddings:  [0.14006133 0.25454733 0.90597545]\n",
      "for:  [0.02751992 0.52801501 0.87223225]\n",
      "happy:  [0.86617615 0.13949386 0.71470175]\n",
      "i:  [0.45088549 0.24233331 0.13500447]\n",
      "learning:  [0.67479332 0.26032334 0.03893893]\n",
      "of:  [-0.04288852  0.33447635  0.66646918]\n",
      "word:  [0.95397666 0.74849415 0.34672029]\n",
      "words:  [0.78594575 0.09947974 0.12200581]\n",
      "❤️:  [0.19603598 0.46924404 0.45229924]\n"
     ]
    }
   ],
   "source": [
    "for word in word2idx:\n",
    "    word_embedding_vector = W1[:, word2idx[word]]\n",
    "    print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ada44",
   "metadata": {},
   "source": [
    "### Option 2: extract embedding vectors from $\\mathbf{W_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d595e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58460309, 0.52428305, 0.69272777, 0.7390903 , 0.24353792,\n",
       "        0.33364289, 0.35743014, 0.17793871, 1.07275855, 0.01823155,\n",
       "        0.69494977, 0.36500688, 0.60653938, 0.26802545],\n",
       "       [0.03906269, 0.18285712, 0.88338516, 0.9133034 , 0.11912604,\n",
       "        0.27286691, 0.37479276, 0.72287055, 0.71118474, 0.7569315 ,\n",
       "        0.85347309, 0.31126915, 0.58444013, 0.16301025],\n",
       "       [0.45131499, 0.89581294, 0.81576306, 0.07516084, 0.34580297,\n",
       "        0.87209223, 0.6115451 , 0.01569921, 0.15053863, 0.65005238,\n",
       "        0.11076281, 0.97617082, 0.22034696, 0.68910976]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f78d2d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:  [0.58460309 0.03906269 0.45131499]\n",
      "am:  [0.52428305 0.18285712 0.89581294]\n",
      "bags:  [0.69272777 0.88338516 0.81576306]\n",
      "because:  [0.7390903  0.9133034  0.07516084]\n",
      "continuous:  [0.24353792 0.11912604 0.34580297]\n",
      "embeddings:  [0.33364289 0.27286691 0.87209223]\n",
      "for:  [0.35743014 0.37479276 0.6115451 ]\n",
      "happy:  [0.17793871 0.72287055 0.01569921]\n",
      "i:  [1.07275855 0.71118474 0.15053863]\n",
      "learning:  [0.01823155 0.7569315  0.65005238]\n",
      "of:  [0.69494977 0.85347309 0.11076281]\n",
      "word:  [0.36500688 0.31126915 0.97617082]\n",
      "words:  [0.60653938 0.58444013 0.22034696]\n",
      "❤️:  [0.26802545 0.16301025 0.68910976]\n"
     ]
    }
   ],
   "source": [
    "for word in word2idx:\n",
    "    word_embedding_vector = W2.T[:, word2idx[word]]\n",
    "    print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f972eb8",
   "metadata": {},
   "source": [
    "### Option 3: extract embedding vectors from $\\mathbf{W_1}$ and $\\mathbf{W_2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334a01d",
   "metadata": {},
   "source": [
    "**Calculate the average of $\\mathbf{W_1}$ and $\\mathbf{W_2^\\top}$, and store the result in `W3`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84602c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47142004, 0.66770051, 0.65738863, 0.64691817, 0.16857596,\n",
       "        0.23685211, 0.19247503, 0.52205743, 0.76182202, 0.34651243,\n",
       "        0.32603063, 0.65949177, 0.69624257, 0.23203072],\n",
       "       [0.09303004, 0.15501723, 0.54627638, 0.69412425, 0.25062986,\n",
       "        0.26370712, 0.45140388, 0.4311822 , 0.47675902, 0.50862742,\n",
       "        0.59397472, 0.52988165, 0.34195993, 0.31612715],\n",
       "       [0.52186478, 0.35984238, 0.67752719, 0.07311274, 0.18016623,\n",
       "        0.88903384, 0.74188868, 0.36520048, 0.14277155, 0.34449566,\n",
       "        0.388616  , 0.66144556, 0.17117638, 0.5707045 ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W3 = (W1+W2.T)/2\n",
    "\n",
    "W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "636471f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:  [0.47142004 0.09303004 0.52186478]\n",
      "am:  [0.66770051 0.15501723 0.35984238]\n",
      "bags:  [0.65738863 0.54627638 0.67752719]\n",
      "because:  [0.64691817 0.69412425 0.07311274]\n",
      "continuous:  [0.16857596 0.25062986 0.18016623]\n",
      "embeddings:  [0.23685211 0.26370712 0.88903384]\n",
      "for:  [0.19247503 0.45140388 0.74188868]\n",
      "happy:  [0.52205743 0.4311822  0.36520048]\n",
      "i:  [0.76182202 0.47675902 0.14277155]\n",
      "learning:  [0.34651243 0.50862742 0.34449566]\n",
      "of:  [0.32603063 0.59397472 0.388616  ]\n",
      "word:  [0.65949177 0.52988165 0.66144556]\n",
      "words:  [0.69624257 0.34195993 0.17117638]\n",
      "❤️:  [0.23203072 0.31612715 0.5707045 ]\n"
     ]
    }
   ],
   "source": [
    "for word in word2idx:\n",
    "    word_embedding_vector = W3[:, word2idx[word]]\n",
    "    print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8eb6a9",
   "metadata": {},
   "source": [
    "### Visualizing the Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60a39782",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = (W1 + W2.T) / 2\n",
    "\n",
    "idx = [word2idx[word] for word in list(word2idx.keys())]\n",
    "\n",
    "X_embs = embs[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1bf5d241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50026389, 0.73237978, 0.72261586, 0.61131672, 0.18367182,\n",
       "        0.26445127, 0.20926378, 0.50941963, 0.7851466 , 0.3551036 ,\n",
       "        0.36558592, 0.66958038, 0.72729761, 0.2513787 ],\n",
       "       [0.20434964, 0.17555037, 0.57708119, 0.72174868, 0.25774475,\n",
       "        0.27841744, 0.45457633, 0.46752984, 0.51441204, 0.57327027,\n",
       "        0.60912028, 0.47592509, 0.29129648, 0.39282984],\n",
       "       [0.53830812, 0.47594713, 0.72205272, 0.12233018, 0.20085814,\n",
       "        0.89130389, 0.7585265 , 0.42491055, 0.22855273, 0.38817039,\n",
       "        0.38403321, 0.66434179, 0.12021671, 0.59753938]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afe5c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "522d2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_embs.T)\n",
    "\n",
    "X_reduced = pca.transform(X_embs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69bc3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6c9e039d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
    "for i, word in idx2word.items():\n",
    "    plt.annotate(word, xy=(X_reduced[i, 0], X_reduced[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99f58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3f1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
