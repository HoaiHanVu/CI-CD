{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06108a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vuhan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy import linalg\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a22a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/shakespeare.txt\") as file:\n",
    "    corpus = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da6de9",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d07a01",
   "metadata": {},
   "source": [
    "- Clean and tokenize the corpus.\n",
    "\n",
    "- Extract the pairs of context words and center word that will make up the training data set for the CBOW model. The context words are the features that will be fed into the model, and the center words are the target values that the model will learn to predict.\n",
    "\n",
    "- Create simple vector representations of the context words (features) and center words (targets) that can be used by the neural network of the CBOW model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec442ade",
   "metadata": {},
   "source": [
    "## 1.1 Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724503a",
   "metadata": {},
   "source": [
    "First, replace all interrupting punctuation signs — such as commas and exclamation marks — with periods.\n",
    "\n",
    "Next, use NLTK's tokenization engine to split the corpus into individual tokens.\n",
    "\n",
    "Finally, get rid of numbers and punctuation other than periods, and convert all the remaining tokens to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84e3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    data = re.sub(r'[,!?;-]', '.', corpus)\n",
    "    data = nltk.word_tokenize(data)\n",
    "    data = [char.lower() for char in data if char.isalpha() or char == '.'\n",
    "#            or emoji.get_emoji_regexp().search(char)\n",
    "           ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f91efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'for', 'a', 'muse', 'of', 'fire', '.', 'that', 'would', 'ascend']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(corpus)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1101a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60976"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8c202",
   "metadata": {},
   "source": [
    "## 1.2 Slicing window of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bd587",
   "metadata": {},
   "source": [
    "Now that we have transformed the corpus into a list of clean tokens, we can slide a window of words across this list. For each window we can extract a center word and the context words.\n",
    "\n",
    "The first argument of this function is a list of words (or tokens). The second argument, `C`, is the context half-size. Recall that for a given center word, the context words are made of `C` words to the left and `C` words to the right of the center word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daea7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(words, C):\n",
    "    i = C\n",
    "    while i < len(words) - C:\n",
    "        center_word = words[i]\n",
    "        context_words = words[i-C:i] + words[i+1:i+C+1]\n",
    "        yield context_words, center_word\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c1f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'a'] for\n",
      "['for', 'muse'] a\n",
      "['a', 'of'] muse\n",
      "['muse', 'fire'] of\n",
      "['of', '.'] fire\n",
      "['fire', 'that'] .\n",
      "['.', 'would'] that\n",
      "['that', 'ascend'] would\n",
      "['would', 'the'] ascend\n",
      "['ascend', 'brightest'] the\n",
      "['the', 'heaven'] brightest\n",
      "['brightest', 'of'] heaven\n",
      "['heaven', 'invention'] of\n"
     ]
    }
   ],
   "source": [
    "for x, y in get_windows(words[:15], 1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488948a",
   "metadata": {},
   "source": [
    "## 1.3 Transforming word into vectors for training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e41ae",
   "metadata": {},
   "source": [
    "### 1.3.1 Mapping words to indices and indices to words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dc7da",
   "metadata": {},
   "source": [
    "The center words will be represented as one-hot vectors, and the vectors that represent context words are also based on one-hot vectors.\n",
    "\n",
    "To create one-hot word vectors, we can start by mapping each unique word to a unique integer (or index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d95f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        data: the data want to pull from\n",
    "    Output:\n",
    "        word2idx: returns dictionary mapping the word to its index\n",
    "        idx2word: returns dictionary mapping the index to its word\n",
    "    \"\"\"\n",
    "    words = sorted(list(set(data)))\n",
    "    n = len(words)\n",
    "    idx = 0\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for k in words:\n",
    "        word2idx[k] = idx\n",
    "        idx2word[idx] = k\n",
    "        idx += 1\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d6835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5775\n",
      "\n",
      "5775\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = get_dict(words)\n",
    "\n",
    "print(len(word2idx))\n",
    "print()\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4b9e1",
   "metadata": {},
   "source": [
    "### 1.3.2 Getting one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83648521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_one_hot_vector(word, word2idx, V):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the letter of corpus want to transform into one hot vector\n",
    "        word2idx: dictionary with key is word and value is index of word in string\n",
    "        V: size of vocabulary\n",
    "    Output:\n",
    "        one_hot_vector: a vector one hot of word\n",
    "    \"\"\"\n",
    "    one_hot_vector = np.zeros(V)\n",
    "    one_hot_vector[word2idx[word]] = 1\n",
    "    \n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0518a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_one_hot_vector('word', word2idx, len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b72619",
   "metadata": {},
   "source": [
    "### 1.3.3 Getting context words vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b9727",
   "metadata": {},
   "source": [
    "To create the vectors that represent context words, we will calculate the average of the one-hot vectors representing the individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67bcaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_words_to_vector(context_words, word2idx, V):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        context_words: list of context words\n",
    "        word2idx: dictionary with key is word and value is index of word in string\n",
    "        V: size of vocabulary\n",
    "    Output:\n",
    "        context_words_vector: vectors of all context words\n",
    "    \"\"\"\n",
    "    context_words_vectors = [word_to_one_hot_vector(w, word2idx, V) for w in context_words]\n",
    "    context_words_vectors = np.mean(context_words_vectors, axis=0)\n",
    "    \n",
    "    return context_words_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe76e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_words_to_vector(['am', 'brightest'], word2idx, len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685f326",
   "metadata": {},
   "source": [
    "## 1.4 Building the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1e0f9",
   "metadata": {},
   "source": [
    "To do this we need to use the sliding window function (`get_windows`) to extract the context words and center words, and we then convert these sets of words into a basic vector representation using `word_to_one_hot_vector` and `context_words_to_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf8c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_example(words, C, word2idx, V):\n",
    "    for context_words, center_word in get_windows(words, C):\n",
    "        yield context_words_to_vector(context_words, word2idx, V),\\\n",
    "              word_to_one_hot_vector(center_word, word2idx, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9881506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context words vector:  [0. 0. 0. ... 0. 0. 0.]\n",
      "Center word vector:  [0. 1. 0. ... 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V = len(word2idx)\n",
    "for context_words_vector, center_word_vector in get_training_example(words[:8], 2, word2idx, V):\n",
    "    print(f'Context words vector:  {context_words_vector}')\n",
    "    print(f'Center word vector:  {center_word_vector}')\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6498a5",
   "metadata": {},
   "source": [
    "## 1.5 Deviding training set into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32abec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(words, word2idx):\n",
    "    idx = []\n",
    "    for word in words:\n",
    "        idx = idx + [word2idx[word]]\n",
    "    return idx\n",
    "\n",
    "def pack_idx_with_frequency(context_words, word2idx):\n",
    "    freq_dict = defaultdict(int)\n",
    "    for word in context_words:\n",
    "        freq_dict[word] += 1\n",
    "    idxs = get_idx(context_words, word2idx)\n",
    "    packed = []\n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        freq = freq_dict[context_words[i]]\n",
    "        packed.append((idx, freq))\n",
    "    return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ba718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, word2idx, V, C):\n",
    "    i = C\n",
    "    while True:\n",
    "        y = np.zeros(V)\n",
    "        x = np.zeros(V)\n",
    "        center_word = data[i]\n",
    "        y[word2idx[center_word]] = 1\n",
    "        context_words = data[(i - C) : i] + data[(i + 1) : (i + C + 1)]\n",
    "        num_ctx_words = len(context_words)\n",
    "        for idx, freq in pack_idx_with_frequency(context_words, word2idx):\n",
    "            x[idx] = freq / num_ctx_words\n",
    "        yield x, y\n",
    "        i += 1\n",
    "        if i >= len(data) - C:\n",
    "#             print(\"i is being set to\", C)\n",
    "            i = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d3414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, word2idx, V, C, batch_size):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for x, y in get_vectors(data, word2idx, V, C):\n",
    "        while len(batch_x) < batch_size:\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "        else:\n",
    "            yield np.array(batch_x).T, np.array(batch_y).T\n",
    "            batch_x = []\n",
    "            batch_y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a99e1c",
   "metadata": {},
   "source": [
    "# 2. The shallow neurals network for continuous bag-of-words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e934b92",
   "metadata": {},
   "source": [
    "## 2.1 Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d3d63",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272fe0",
   "metadata": {},
   "source": [
    "ReLU is used to calculate the values of the hidden layer, in the following formulas:\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{z_1} &= \\mathbf{W_1}\\mathbf{x} + \\mathbf{b_1}  \\ \\\\\n",
    " \\mathbf{h} &= \\mathrm{ReLU}(\\mathbf{z_1})  \\ \\\\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b7d7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b6cdb",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95472c61",
   "metadata": {},
   "source": [
    "The second activation function that we need is softmax. This function is used to calculate the values of the output layer of the neural network, using the following formulas:\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{z_2} &= \\mathbf{W_2}\\mathbf{h} + \\mathbf{b_2}   \\\\\\\n",
    " \\mathbf{\\hat y} &= \\mathrm{softmax}(\\mathbf{z_2})   \\\\\\\n",
    "\\end{align}\n",
    "\n",
    "To calculate softmax of a vector $\\mathbf{z}$, the $i$-th component of the resulting vector is given by:\n",
    "\n",
    "$$ \\textrm{softmax}(\\textbf{z})_i = \\frac{e^{z_i} }{\\sum\\limits_{j=1}^{V} e^{z_j} }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24f41810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    yhat = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "539e07cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.73105858, 0.88079708],\n",
       "       [0.5       , 0.26894142, 0.11920292]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the function\n",
    "tmp = np.array([[1,2,3],\n",
    "                [1,1,1]\n",
    "               ])\n",
    "tmp_sm = softmax(tmp)\n",
    "display(tmp_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56ebc",
   "metadata": {},
   "source": [
    "## 2.2 Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be3b2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cost(y, yhat, batch_size):\n",
    "#     loss = np.sum(np.multiply(np.log(yhat), y))\n",
    "    \n",
    "#     cost = -1/batch_size * loss\n",
    "#     cost = np.squeeze(cost)\n",
    "    \n",
    "#     return cost\n",
    "\n",
    "\n",
    "def compute_cost(y, yhat, batch_size):\n",
    "\n",
    "    # cost function \n",
    "    logprobs = np.multiply(np.log(yhat),y)\n",
    "    cost = - 1/batch_size * np.sum(logprobs)\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f342d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_x.shape (5775, 4)\n",
      "tmp_y.shape (5775, 4)\n",
      "tmp_W1.shape (50, 5775)\n",
      "tmp_W2.shape (5775, 50)\n",
      "tmp_b1.shape (50, 1)\n",
      "tmp_b2.shape (5775, 1)\n",
      "tmp_z.shape: (5775, 4)\n",
      "tmp_h.shape: (50, 4)\n",
      "tmp_yhat.shape: (5775, 4)\n",
      "call compute_cost\n",
      "tmp_cost 10.0494\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "tmp_C = 2\n",
    "tmp_N = 50\n",
    "tmp_batch_size = 4\n",
    "tmp_word2Ind, tmp_Ind2word = get_dict(words)\n",
    "tmp_V = len(word2idx)\n",
    "\n",
    "tmp_x, tmp_y = next(get_batches(words, tmp_word2Ind, tmp_V,tmp_C, tmp_batch_size))\n",
    "        \n",
    "print(f\"tmp_x.shape {tmp_x.shape}\")\n",
    "print(f\"tmp_y.shape {tmp_y.shape}\")\n",
    "\n",
    "tmp_W1, tmp_W2, tmp_b1, tmp_b2 = initialize_model(tmp_N,tmp_V)\n",
    "\n",
    "print(f\"tmp_W1.shape {tmp_W1.shape}\")\n",
    "print(f\"tmp_W2.shape {tmp_W2.shape}\")\n",
    "print(f\"tmp_b1.shape {tmp_b1.shape}\")\n",
    "print(f\"tmp_b2.shape {tmp_b2.shape}\")\n",
    "\n",
    "tmp_z, tmp_h = forward_prop(tmp_x, tmp_W1, tmp_W2, tmp_b1, tmp_b2)\n",
    "print(f\"tmp_z.shape: {tmp_z.shape}\")\n",
    "print(f\"tmp_h.shape: {tmp_h.shape}\")\n",
    "\n",
    "tmp_yhat = softmax(tmp_z)\n",
    "print(f\"tmp_yhat.shape: {tmp_yhat.shape}\")\n",
    "\n",
    "tmp_cost = compute_cost(tmp_y, tmp_yhat, tmp_batch_size)\n",
    "print(\"call compute_cost\")\n",
    "print(f\"tmp_cost {tmp_cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424beed",
   "metadata": {},
   "source": [
    "## 2.3 Foward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eae12",
   "metadata": {},
   "source": [
    "### 2.3.1 Initialization of the weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0734c",
   "metadata": {},
   "source": [
    "- The first matrix ($W_1$) is of dimension $N \\times V$, where $V$ is the number of words in vocabulary and $N$ is the dimension of word vector.\n",
    "- The second matrix ($W_2$) is of dimension $V \\times N$. \n",
    "- Vector $b_1$ has dimensions $N\\times 1$\n",
    "- Vector $b_2$ has dimensions  $V\\times 1$. \n",
    "- $b_1$ and $b_2$ are the bias vectors of the linear layers from matrices $W_1$ and $W_2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb15452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(N, V, random_seed=1):\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    W1 = np.random.rand(N, V)\n",
    "    b1 = np.random.rand(N, 1)\n",
    "    W2 = np.random.rand(V, N)\n",
    "    b2 = np.random.rand(V, 1)\n",
    "    \n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d57c19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_W1.shape: (4, 10)\n",
      "tmp_W2.shape: (10, 4)\n",
      "tmp_b1.shape: (4, 1)\n",
      "tmp_b2.shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "tmp_N = 4\n",
    "tmp_V = 10\n",
    "tmp_W1, tmp_W2, tmp_b1, tmp_b2 = initialize_model(tmp_N,tmp_V)\n",
    "assert tmp_W1.shape == ((tmp_N,tmp_V))\n",
    "assert tmp_W2.shape == ((tmp_V,tmp_N))\n",
    "print(f\"tmp_W1.shape: {tmp_W1.shape}\")\n",
    "print(f\"tmp_W2.shape: {tmp_W2.shape}\")\n",
    "print(f\"tmp_b1.shape: {tmp_b1.shape}\")\n",
    "print(f\"tmp_b2.shape: {tmp_b2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a9b42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_prop(x, W1, W2, b1, b2):\n",
    "#     h = np.dot(W1, x) + b1\n",
    "#     h = np.maximum(0, h)\n",
    "#     z = np.dot(W2, h) + b2\n",
    "    \n",
    "#     return z, h\n",
    "\n",
    "def forward_prop(x, W1, W2, b1, b2):\n",
    "    '''\n",
    "    Inputs: \n",
    "        x:  average one hot vector for the context \n",
    "        W1, W2, b1, b2:  matrices and biases to be learned\n",
    "     Outputs: \n",
    "        z:  output score vector\n",
    "    '''\n",
    "    \n",
    "    ### START CODE HERE (Replace instances of 'None' with your own code) ###\n",
    "    # Calculate h\n",
    "    h = np.dot(W1, x) + b1\n",
    "  \n",
    "    # Apply the relu on h, \n",
    "    # store the relu in h\n",
    "    h = np.maximum(0, h)\n",
    "         \n",
    "    # Calculate z\n",
    "    z = np.dot(W2, h) + b2\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return z, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10b8acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x has shape (3, 1)\n",
      "N is 2 and vocabulary size V is 3\n",
      "call forward_prop\n",
      "\n",
      "z has shape (3, 1)\n",
      "z has values:\n",
      "[[0.65235935]\n",
      " [1.38784779]\n",
      " [1.03496989]]\n",
      "\n",
      "h has shape (2, 1)\n",
      "h has values:\n",
      "[[0.9065847 ]\n",
      " [0.49231662]]\n"
     ]
    }
   ],
   "source": [
    "tmp_N = 2\n",
    "tmp_V = 3\n",
    "tmp_x = np.array([[0,1,0]]).T\n",
    "#print(tmp_x)\n",
    "tmp_W1, tmp_W2, tmp_b1, tmp_b2 = initialize_model(N=tmp_N,V=tmp_V, random_seed=1)\n",
    "\n",
    "print(f\"x has shape {tmp_x.shape}\")\n",
    "print(f\"N is {tmp_N} and vocabulary size V is {tmp_V}\")\n",
    "\n",
    "# call function\n",
    "tmp_z, tmp_h = forward_prop(tmp_x, tmp_W1, tmp_W2, tmp_b1, tmp_b2)\n",
    "print(\"call forward_prop\")\n",
    "print()\n",
    "# Look at output\n",
    "print(f\"z has shape {tmp_z.shape}\")\n",
    "print(\"z has values:\")\n",
    "print(tmp_z)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"h has shape {tmp_h.shape}\")\n",
    "print(\"h has values:\")\n",
    "print(tmp_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436f5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "880d653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exp = get_training_example(words, 2, word2idx, V)\n",
    "\n",
    "x_arr, y_arr = next(training_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ff9612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X array: [0. 0. 0. ... 0. 0. 0.]\n",
      "Y array [0. 1. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('X array:', x_arr)\n",
    "print('Y array', y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f168d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_arr.copy().reshape((V, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d0a6eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_arr.copy().reshape((V, 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3681d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, W2, b1, b2 = initialize_model(N, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cec6034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.88322531]\n",
      " [2.06552369]\n",
      " [2.438463  ]\n",
      " ...\n",
      " [1.96973529]\n",
      " [1.70202752]\n",
      " [1.34899408]]\n"
     ]
    }
   ],
   "source": [
    "z, h = forward_prop(x, W1, W2, b1, b2)\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd21efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08961252],\n",
       "       [1.39446122],\n",
       "       [0.67178827]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b51e7879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.865703412956584"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(y, softmax(z), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40964c4b",
   "metadata": {},
   "source": [
    "## 2.4 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9813e6a",
   "metadata": {},
   "source": [
    "The formulas will implement for backpropagation are the following.\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right )\\mathbf{x}^\\top \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_2}} &= (\\mathbf{\\hat{y}} - \\mathbf{y})\\mathbf{h^\\top} \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right ) \\\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_2}} &= \\mathbf{\\hat{y}} - \\mathbf{y} \\\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0bd50e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
    "#     grad_b2 = 1/batch_size * np.dot(yhat - y, np.ones((batch_size, 1)))\n",
    "#     grad_W2 = 1/batch_size * np.dot(yhat - y, h.T)\n",
    "#     grad_b1 = 1/batch_size * np.dot(relu(np.dot(W2.T, yhat -y)), np.ones((batch_size, 1)))\n",
    "#     grad_W1 = 1/batch_size * np.dot(relu(np.dot(W2.T, yhat - y)), x.T)\n",
    "    \n",
    "#     return grad_W1, grad_W2, grad_b1, grad_b2\n",
    "\n",
    "def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
    "    '''\n",
    "    Inputs: \n",
    "        x:  average one hot vector for the context \n",
    "        yhat: prediction (estimate of y)\n",
    "        y:  target vector\n",
    "        h:  hidden vector (see eq. 1)\n",
    "        W1, W2, b1, b2:  matrices and biases  \n",
    "        batch_size: batch size \n",
    "     Outputs: \n",
    "        grad_W1, grad_W2, grad_b1, grad_b2:  gradients of matrices and biases   \n",
    "    '''\n",
    "    ### START CODE HERE (Replace instanes of 'None' with your code) ###\n",
    "    # Compute l1 as W2^T (Yhat - Y)\n",
    "    # and re-use it whenever you see W2^T (Yhat - Y) used to compute a gradient\n",
    "    l1 = np.dot(W2.T, yhat-y)\n",
    "\n",
    "    # Apply relu to l1\n",
    "    l1 = np.maximum(0, l1)\n",
    "\n",
    "    # compute the gradient for W1\n",
    "    grad_W1 = 1/batch_size * np.dot(l1, x.T)\n",
    "\n",
    "    # Compute gradient of W2\n",
    "    grad_W2 = 1/batch_size * np.dot(yhat -y, h.T)\n",
    "    \n",
    "    # compute gradient for b1\n",
    "    grad_b1 = 1/batch_size * np.dot(l1,np.ones((batch_size,1)))\n",
    "\n",
    "    # compute gradient for b2\n",
    "    grad_b2 = 1/batch_size * np.dot(yhat-y,np.ones((batch_size,1)))\n",
    "    ### END CODE HERE ####\n",
    "    \n",
    "    return grad_W1, grad_W2, grad_b1, grad_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1eebd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get a batch of data\n",
      "tmp_x.shape (5775, 4)\n",
      "tmp_y.shape (5775, 4)\n",
      "\n",
      "Initialize weights and biases\n",
      "tmp_W1.shape (50, 5775)\n",
      "tmp_W2.shape (5775, 50)\n",
      "tmp_b1.shape (50, 1)\n",
      "tmp_b2.shape (5775, 1)\n",
      "\n",
      "Forwad prop to get z and h\n",
      "tmp_z.shape: (5775, 4)\n",
      "tmp_h.shape: (50, 4)\n",
      "\n",
      "Get yhat by calling softmax\n",
      "tmp_yhat.shape: (5775, 4)\n",
      "\n",
      "call back_prop\n",
      "tmp_grad_W1.shape (50, 5775)\n",
      "tmp_grad_W2.shape (5775, 50)\n",
      "tmp_grad_b1.shape (50, 1)\n",
      "tmp_grad_b2.shape (5775, 1)\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "tmp_C = 2\n",
    "tmp_N = 50\n",
    "tmp_batch_size = 4\n",
    "tmp_word2Ind, tmp_Ind2word = get_dict(words)\n",
    "tmp_V = len(word2idx)\n",
    "\n",
    "\n",
    "# get a batch of data\n",
    "tmp_x, tmp_y = next(get_batches(words, tmp_word2Ind, tmp_V,tmp_C, tmp_batch_size))\n",
    "\n",
    "print(\"get a batch of data\")\n",
    "print(f\"tmp_x.shape {tmp_x.shape}\")\n",
    "print(f\"tmp_y.shape {tmp_y.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"Initialize weights and biases\")\n",
    "tmp_W1, tmp_W2, tmp_b1, tmp_b2 = initialize_model(tmp_N,tmp_V)\n",
    "\n",
    "print(f\"tmp_W1.shape {tmp_W1.shape}\")\n",
    "print(f\"tmp_W2.shape {tmp_W2.shape}\")\n",
    "print(f\"tmp_b1.shape {tmp_b1.shape}\")\n",
    "print(f\"tmp_b2.shape {tmp_b2.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"Forwad prop to get z and h\")\n",
    "tmp_z, tmp_h = forward_prop(tmp_x, tmp_W1, tmp_W2, tmp_b1, tmp_b2)\n",
    "print(f\"tmp_z.shape: {tmp_z.shape}\")\n",
    "print(f\"tmp_h.shape: {tmp_h.shape}\")\n",
    "\n",
    "print()\n",
    "print(\"Get yhat by calling softmax\")\n",
    "tmp_yhat = softmax(tmp_z)\n",
    "print(f\"tmp_yhat.shape: {tmp_yhat.shape}\")\n",
    "\n",
    "tmp_m = (2*tmp_C)\n",
    "tmp_grad_W1, tmp_grad_W2, tmp_grad_b1, tmp_grad_b2 = back_prop(tmp_x, tmp_yhat, tmp_y, tmp_h, tmp_W1, tmp_W2, tmp_b1, tmp_b2, tmp_batch_size)\n",
    "\n",
    "print()\n",
    "print(\"call back_prop\")\n",
    "print(f\"tmp_grad_W1.shape {tmp_grad_W1.shape}\")\n",
    "print(f\"tmp_grad_W2.shape {tmp_grad_W2.shape}\")\n",
    "print(f\"tmp_grad_b1.shape {tmp_grad_b1.shape}\")\n",
    "print(f\"tmp_grad_b2.shape {tmp_grad_b2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9850eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58f1743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = softmax(z)\n",
    "\n",
    "grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11cffb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 5775\n",
      "Shape of W1: (3, 5775)\n",
      "Shape of W2: (5775, 3)\n",
      "Shape of b1: (3, 1)\n",
      "Shape of b2: (5775, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Size of vocabulary: {}'.format(V))\n",
    "print('Shape of W1: {}'.format(grad_W1.shape))\n",
    "print('Shape of W2: {}'.format(grad_W2.shape))\n",
    "print('Shape of b1: {}'.format(grad_b1.shape))\n",
    "print('Shape of b2: {}'.format(grad_b2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b177c80",
   "metadata": {},
   "source": [
    "## 2.5 Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbad56",
   "metadata": {},
   "source": [
    "During the gradient descent phase, we will update the weights and biases by subtracting $\\alpha$ times the gradient from the original matrices and vectors, using the following formulas.\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{W_1} &:= \\mathbf{W_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_1}} \\\\\\\n",
    " \\mathbf{W_2} &:= \\mathbf{W_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_2}} \\\\\\\n",
    " \\mathbf{b_1} &:= \\mathbf{b_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_1}} \\\\\\\n",
    " \\mathbf{b_2} &:= \\mathbf{b_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_2}} \\\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40ecc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(data, word2idx, N, V, num_iters, alpha, batch_sizes,\n",
    "                     initialize_model=initialize_model, get_batches=get_batches, forward_prop=forward_prop,\n",
    "                     softmax=softmax, compute_cost=compute_cost, back_prop=back_prop, random_seed=42):\n",
    "    '''\n",
    "    \n",
    "      Inputs: \n",
    "        data:      text/list of words\n",
    "        word2idx:  words to Indices\n",
    "        N:         dimension of hidden vector  \n",
    "        V:         dimension of vocabulary \n",
    "        num_iters: number of iterations  \n",
    "        random_seed: random seed to initialize the model's matrices and vectors\n",
    "        initialize_model: your implementation of the function to initialize the model\n",
    "        get_batches: function to get the data in batches\n",
    "        forward_prop: your implementation of the function to perform forward propagation\n",
    "        softmax: your implementation of the softmax function\n",
    "        compute_cost: cost function (Cross entropy)\n",
    "        back_prop: your implementation of the function to perform backward propagation\n",
    "     Outputs: \n",
    "        W1, W2, b1, b2:  updated matrices and biases after num_iters iterations\n",
    "\n",
    "    '''\n",
    "    W1, W2, b1, b2 = initialize_model(N, V, random_seed=random_seed)\n",
    "    batch_size = batch_sizes\n",
    "    \n",
    "    iters = 0\n",
    "    C = 2\n",
    "    \n",
    "    for x, y in get_batches(data, word2idx, V, C, batch_size):\n",
    "        z, h = forward_prop(x, W1, W2, b1, b2)\n",
    "        \n",
    "        yhat = softmax(z)\n",
    "        \n",
    "        cost = compute_cost(y, yhat, batch_size)\n",
    "        if (iters) % 10 == 0 and iters != 0:\n",
    "            print('Iters: {} cost: {:.5f}'.format(iters, cost))\n",
    "        \n",
    "        grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size)\n",
    "        \n",
    "        W1 = W1 - alpha * grad_W1\n",
    "        W2 = W2 - alpha * grad_W2\n",
    "        b1 = b1 - alpha * grad_b1\n",
    "        b2 = b2 - alpha * grad_b2\n",
    "        \n",
    "        iters += 1\n",
    "        if iters == num_iters:\n",
    "            break\n",
    "        if iters % 100 == 0:\n",
    "            alpha *= 0.66\n",
    "            \n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8e97e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters: 10 cost: 13.04536\n",
      "Iters: 20 cost: 19.31177\n",
      "Iters: 30 cost: 4.41144\n",
      "Iters: 40 cost: 19.97878\n",
      "Iters: 50 cost: 3.86423\n",
      "Iters: 60 cost: 4.52410\n",
      "Iters: 70 cost: 16.76341\n",
      "Iters: 80 cost: 9.98704\n",
      "Iters: 90 cost: 15.92725\n",
      "Iters: 100 cost: 5.87687\n",
      "Iters: 110 cost: 10.91660\n",
      "Iters: 120 cost: 7.13941\n",
      "Iters: 130 cost: 10.57703\n",
      "Iters: 140 cost: 5.24777\n"
     ]
    }
   ],
   "source": [
    "N = 300\n",
    "V = len(word2idx)\n",
    "num_iters = 150\n",
    "alpha = 0.03\n",
    "batch_sizes = 128\n",
    "\n",
    "W1, W2, b1, b2 = gradient_descent(words, word2idx, N, V, num_iters, alpha, batch_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635c12f",
   "metadata": {},
   "source": [
    "# 3. Extracting & Visualizing word embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651f489",
   "metadata": {},
   "source": [
    "### Option 1: extract embedding vectors from $\\mathbf{W_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e009cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5775)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79487258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23401216, 0.93107723, 0.73199394, ..., 0.25715235, 0.71938816,\n",
       "        0.02812151],\n",
       "       [0.27682363, 0.60864366, 0.14609657, ..., 0.94505055, 0.54820377,\n",
       "        0.95317754],\n",
       "       [0.0883076 , 0.71227936, 0.81223954, ..., 0.61342626, 0.02977191,\n",
       "        0.50414849]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99a362",
   "metadata": {},
   "source": [
    "The first column, which is a 3-element vector, is the embedding vector of the first word of your vocabulary. The second column is the word embedding vector for the second word, and so on.\n",
    "\n",
    "The first, second, etc. words are ordered as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c071d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in word2idx:\n",
    "#     word_embedding_vector = W1[:, word2idx[word]]\n",
    "#     print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ada44",
   "metadata": {},
   "source": [
    "### Option 2: extract embedding vectors from $\\mathbf{W_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d595e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42039249, 0.7516403 , 0.19970316, ..., 0.94318466, 0.26937761,\n",
       "        0.17784783],\n",
       "       [0.73360901, 0.30124578, 0.988892  , ..., 0.21550699, 0.87660248,\n",
       "        0.72034645],\n",
       "       [1.00605264, 0.97533404, 0.00695004, ..., 0.79296809, 0.09817396,\n",
       "        0.17463643]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f78d2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in word2idx:\n",
    "#     word_embedding_vector = W2.T[:, word2idx[word]]\n",
    "#     print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f972eb8",
   "metadata": {},
   "source": [
    "### Option 3: extract embedding vectors from $\\mathbf{W_1}$ and $\\mathbf{W_2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334a01d",
   "metadata": {},
   "source": [
    "**Calculate the average of $\\mathbf{W_1}$ and $\\mathbf{W_2^\\top}$, and store the result in `W3`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84602c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82720233, 0.84135876, 0.46584855, ..., 0.60016851, 0.49438288,\n",
       "        0.10298467],\n",
       "       [0.50521632, 0.45494472, 0.56749428, ..., 0.58027877, 0.71240313,\n",
       "        0.83676199],\n",
       "       [0.54718012, 0.8438067 , 0.40959479, ..., 0.70319718, 0.06397293,\n",
       "        0.33939246]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W3 = (W1+W2.T)/2\n",
    "\n",
    "W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "636471f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in word2idx:\n",
    "#     word_embedding_vector = W3[:, word2idx[word]]\n",
    "#     print('{}:  {}'.format(word, word_embedding_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8eb6a9",
   "metadata": {},
   "source": [
    "### Visualizing the Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "60a39782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_words = ['king', 'queen','lord','man', 'woman','dog','wolf',\n",
    "         'rich','happy','sad']\n",
    "\n",
    "embs = (W1 + W2.T) / 2\n",
    "\n",
    "idx = [word2idx[word] for word in tmp_words]\n",
    "\n",
    "X_embs = embs[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "828f564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 300) [2744, 3949, 2960, 3022, 5672, 1452, 5671, 4189, 2315, 4276]\n"
     ]
    }
   ],
   "source": [
    "words = ['king', 'queen','lord','man', 'woman','dog','wolf',\n",
    "         'rich','happy','sad']\n",
    "\n",
    "embs = (W1.T + W2)/2.0\n",
    " \n",
    "# given a list of words and the embeddings, it returns a matrix with all the embeddings\n",
    "idx = [word2idx[word] for word in words]\n",
    "X = embs[idx, :]\n",
    "print(X.shape, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1bf5d241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75617617, 0.55123138, 0.15103453, ..., 0.36697407, 0.52095975,\n",
       "        0.57413934],\n",
       "       [0.90429271, 0.39500144, 0.58925456, ..., 0.63943387, 0.43933398,\n",
       "        0.30720252],\n",
       "       [0.40381387, 0.71692826, 0.90895271, ..., 0.41247267, 0.53174454,\n",
       "        0.61525898],\n",
       "       ...,\n",
       "       [0.28025292, 0.28082184, 0.40141138, ..., 0.49284381, 0.62399881,\n",
       "        0.69067546],\n",
       "       [0.28470947, 0.13349295, 0.75493614, ..., 0.74415333, 0.37753939,\n",
       "        0.77190117],\n",
       "       [0.65296523, 0.51266489, 0.43219641, ..., 0.60016587, 0.55731318,\n",
       "        0.90103017]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "afe5c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 10)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "522d2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_embs.T)\n",
    "\n",
    "X_reduced = pca.transform(X_embs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69bc3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c9e039d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1])\n",
    "for i, word in enumerate(tmp_words):\n",
    "    plt.annotate(word, xy=(X_reduced[i, 0], X_reduced[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99f58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3f1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
