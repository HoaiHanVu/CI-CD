{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f0f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vuhan/.pyenv/versions/3.7.9/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/vuhan/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/vuhan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import trax\n",
    "import trax.fastmath.numpy as np\n",
    "from trax import layers as tl\n",
    "from trax import fastmath\n",
    "from utils import Layer, load_tweets, process_tweet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7227a09",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7e71d",
   "metadata": {},
   "source": [
    "## 1.1 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b447f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split():\n",
    "    all_pos_tws, all_neg_tws = load_tweets()\n",
    "    \n",
    "    print(f\"The number of positive tweets: {len(all_pos_tws)}\")\n",
    "    print(f\"The number of negative tweets: {len(all_neg_tws)}\")\n",
    "\n",
    "    val_pos = all_pos_tws[4000: ]\n",
    "    train_pos = all_pos_tws[: 4000]\n",
    "    \n",
    "    val_neg = all_neg_tws[4000: ]\n",
    "    train_neg = all_neg_tws[: 4000]\n",
    "    \n",
    "    train_x = train_pos + train_neg\n",
    "    val_x = val_pos + val_neg\n",
    "    \n",
    "    train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "    val_y = np.append(np.ones(len(val_pos)), np.zeros(len(val_neg)))\n",
    "    \n",
    "    return train_pos, train_neg, train_x, train_y, val_pos, val_neg, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf2b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive tweets: 5000\n",
      "The number of negative tweets: 5000\n"
     ]
    }
   ],
   "source": [
    "train_pos, train_neg, train_x, train_y, val_pos, val_neg, val_x, val_y = train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33990d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_x: 8000\n",
      "Length of val_x: 2000\n"
     ]
    }
   ],
   "source": [
    "print('Length of train_x: {}'.format(len(train_x)))\n",
    "print('Length of val_x: {}'.format(len(val_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf5af9",
   "metadata": {},
   "source": [
    "## 1.2 Building the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991620a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(data):\n",
    "    \n",
    "    Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
    "    \n",
    "    for tweet in data:\n",
    "        processed_tweet = process_tweet(tweet)\n",
    "        for word in processed_tweet:\n",
    "            if word not in Vocab:\n",
    "                Vocab[word] = len(Vocab)\n",
    "    return Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c6a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocab = get_vocab(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c262247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab: 9088\n"
     ]
    }
   ],
   "source": [
    "print('Total words in vocab: {}'.format(len(Vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49814d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__PAD__': 0,\n",
       " '__</e>__': 1,\n",
       " '__UNK__': 2,\n",
       " 'followfriday': 3,\n",
       " 'top': 4,\n",
       " 'engag': 5,\n",
       " 'member': 6,\n",
       " 'commun': 7,\n",
       " 'week': 8,\n",
       " ':)': 9,\n",
       " 'hey': 10,\n",
       " 'jame': 11,\n",
       " 'odd': 12,\n",
       " ':/': 13,\n",
       " 'pleas': 14,\n",
       " 'call': 15,\n",
       " 'contact': 16,\n",
       " 'centr': 17,\n",
       " '02392441234': 18,\n",
       " 'abl': 19,\n",
       " 'assist': 20,\n",
       " 'mani': 21,\n",
       " 'thank': 22,\n",
       " 'listen': 23,\n",
       " 'last': 24,\n",
       " 'night': 25,\n",
       " 'bleed': 26,\n",
       " 'amaz': 27,\n",
       " 'track': 28,\n",
       " 'scotland': 29,\n",
       " 'congrat': 30,\n",
       " 'yeaaah': 31,\n",
       " 'yipppi': 32,\n",
       " 'accnt': 33,\n",
       " 'verifi': 34,\n",
       " 'rqst': 35,\n",
       " 'succeed': 36,\n",
       " 'got': 37,\n",
       " 'blue': 38,\n",
       " 'tick': 39,\n",
       " 'mark': 40,\n",
       " 'fb': 41,\n",
       " 'profil': 42,\n",
       " '15': 43,\n",
       " 'day': 44,\n",
       " 'one': 45,\n",
       " 'irresist': 46,\n",
       " 'flipkartfashionfriday': 47,\n",
       " 'like': 48,\n",
       " 'keep': 49,\n",
       " 'love': 50,\n",
       " 'custom': 51,\n",
       " 'wait': 52,\n",
       " 'long': 53,\n",
       " 'hope': 54,\n",
       " 'enjoy': 55,\n",
       " 'happi': 56,\n",
       " 'friday': 57,\n",
       " 'lwwf': 58,\n",
       " 'second': 59,\n",
       " 'thought': 60,\n",
       " '‚Äô': 61,\n",
       " 'enough': 62,\n",
       " 'time': 63,\n",
       " 'dd': 64,\n",
       " 'new': 65,\n",
       " 'short': 66,\n",
       " 'enter': 67,\n",
       " 'system': 68,\n",
       " 'sheep': 69,\n",
       " 'must': 70,\n",
       " 'buy': 71,\n",
       " 'jgh': 72,\n",
       " 'go': 73,\n",
       " 'bayan': 74,\n",
       " ':d': 75,\n",
       " 'bye': 76,\n",
       " 'act': 77,\n",
       " 'mischiev': 78,\n",
       " 'etl': 79,\n",
       " 'layer': 80,\n",
       " 'in-hous': 81,\n",
       " 'wareh': 82,\n",
       " 'app': 83,\n",
       " 'katamari': 84,\n",
       " 'well': 85,\n",
       " '‚Ä¶': 86,\n",
       " 'name': 87,\n",
       " 'impli': 88,\n",
       " ':p': 89,\n",
       " 'influenc': 90,\n",
       " 'big': 91,\n",
       " '...': 92,\n",
       " 'juici': 93,\n",
       " 'selfi': 94,\n",
       " 'follow': 95,\n",
       " 'perfect': 96,\n",
       " 'alreadi': 97,\n",
       " 'know': 98,\n",
       " \"what'\": 99,\n",
       " 'great': 100,\n",
       " 'opportun': 101,\n",
       " 'junior': 102,\n",
       " 'triathlet': 103,\n",
       " 'age': 104,\n",
       " '12': 105,\n",
       " '13': 106,\n",
       " 'gatorad': 107,\n",
       " 'seri': 108,\n",
       " 'get': 109,\n",
       " 'entri': 110,\n",
       " 'lay': 111,\n",
       " 'greet': 112,\n",
       " 'card': 113,\n",
       " 'rang': 114,\n",
       " 'print': 115,\n",
       " 'today': 116,\n",
       " 'job': 117,\n",
       " ':-)': 118,\n",
       " \"friend'\": 119,\n",
       " 'lunch': 120,\n",
       " 'yummm': 121,\n",
       " 'nostalgia': 122,\n",
       " 'tb': 123,\n",
       " 'ku': 124,\n",
       " 'id': 125,\n",
       " 'conflict': 126,\n",
       " 'help': 127,\n",
       " \"here'\": 128,\n",
       " 'screenshot': 129,\n",
       " 'work': 130,\n",
       " 'hi': 131,\n",
       " 'liv': 132,\n",
       " 'hello': 133,\n",
       " 'need': 134,\n",
       " 'someth': 135,\n",
       " 'u': 136,\n",
       " 'fm': 137,\n",
       " 'twitter': 138,\n",
       " '‚Äî': 139,\n",
       " 'sure': 140,\n",
       " 'thing': 141,\n",
       " 'dm': 142,\n",
       " 'x': 143,\n",
       " \"i'v\": 144,\n",
       " 'heard': 145,\n",
       " 'four': 146,\n",
       " 'season': 147,\n",
       " 'pretti': 148,\n",
       " 'dope': 149,\n",
       " 'penthous': 150,\n",
       " 'obv': 151,\n",
       " 'gobigorgohom': 152,\n",
       " 'fun': 153,\n",
       " \"y'all\": 154,\n",
       " 'yeah': 155,\n",
       " 'suppos': 156,\n",
       " 'lol': 157,\n",
       " 'chat': 158,\n",
       " 'bit': 159,\n",
       " 'youth': 160,\n",
       " 'üíÖüèΩ': 161,\n",
       " 'üíã': 162,\n",
       " 'seen': 163,\n",
       " 'year': 164,\n",
       " 'rest': 165,\n",
       " 'goe': 166,\n",
       " 'quickli': 167,\n",
       " 'bed': 168,\n",
       " 'music': 169,\n",
       " 'fix': 170,\n",
       " 'dream': 171,\n",
       " 'spiritu': 172,\n",
       " 'ritual': 173,\n",
       " 'festiv': 174,\n",
       " 'n√©pal': 175,\n",
       " 'begin': 176,\n",
       " 'line-up': 177,\n",
       " 'left': 178,\n",
       " 'see': 179,\n",
       " 'sarah': 180,\n",
       " 'send': 181,\n",
       " 'us': 182,\n",
       " 'email': 183,\n",
       " 'bitsy@bitdefender.com': 184,\n",
       " \"we'll\": 185,\n",
       " 'asap': 186,\n",
       " 'kik': 187,\n",
       " 'hatessuc': 188,\n",
       " '32429': 189,\n",
       " 'kikm': 190,\n",
       " 'lgbt': 191,\n",
       " 'tinder': 192,\n",
       " 'nsfw': 193,\n",
       " 'akua': 194,\n",
       " 'cumshot': 195,\n",
       " 'come': 196,\n",
       " 'hous': 197,\n",
       " 'nsn_supplement': 198,\n",
       " 'effect': 199,\n",
       " 'press': 200,\n",
       " 'releas': 201,\n",
       " 'distribut': 202,\n",
       " 'result': 203,\n",
       " 'link': 204,\n",
       " 'remov': 205,\n",
       " 'pressreleas': 206,\n",
       " 'newsdistribut': 207,\n",
       " 'bam': 208,\n",
       " 'bestfriend': 209,\n",
       " 'lot': 210,\n",
       " 'warsaw': 211,\n",
       " '<3': 212,\n",
       " 'x46': 213,\n",
       " 'everyon': 214,\n",
       " 'watch': 215,\n",
       " 'documentari': 216,\n",
       " 'earthl': 217,\n",
       " 'youtub': 218,\n",
       " 'support': 219,\n",
       " 'buuut': 220,\n",
       " 'oh': 221,\n",
       " 'look': 222,\n",
       " 'forward': 223,\n",
       " 'visit': 224,\n",
       " 'next': 225,\n",
       " 'letsgetmessi': 226,\n",
       " 'jo': 227,\n",
       " 'make': 228,\n",
       " 'feel': 229,\n",
       " 'better': 230,\n",
       " 'never': 231,\n",
       " 'anyon': 232,\n",
       " 'kpop': 233,\n",
       " 'flesh': 234,\n",
       " 'good': 235,\n",
       " 'girl': 236,\n",
       " 'best': 237,\n",
       " 'wish': 238,\n",
       " 'reason': 239,\n",
       " 'epic': 240,\n",
       " 'soundtrack': 241,\n",
       " 'shout': 242,\n",
       " 'ad': 243,\n",
       " 'video': 244,\n",
       " 'playlist': 245,\n",
       " 'would': 246,\n",
       " 'dear': 247,\n",
       " 'jordan': 248,\n",
       " 'okay': 249,\n",
       " 'fake': 250,\n",
       " 'gameplay': 251,\n",
       " ';)': 252,\n",
       " 'haha': 253,\n",
       " 'im': 254,\n",
       " 'kid': 255,\n",
       " 'stuff': 256,\n",
       " 'exactli': 257,\n",
       " 'product': 258,\n",
       " 'line': 259,\n",
       " 'etsi': 260,\n",
       " 'shop': 261,\n",
       " 'check': 262,\n",
       " 'vacat': 263,\n",
       " 'recharg': 264,\n",
       " 'normal': 265,\n",
       " 'charger': 266,\n",
       " 'asleep': 267,\n",
       " 'talk': 268,\n",
       " 'sooo': 269,\n",
       " 'someon': 270,\n",
       " 'text': 271,\n",
       " 'ye': 272,\n",
       " 'bet': 273,\n",
       " \"he'll\": 274,\n",
       " 'fit': 275,\n",
       " 'hear': 276,\n",
       " 'speech': 277,\n",
       " 'piti': 278,\n",
       " 'green': 279,\n",
       " 'garden': 280,\n",
       " 'midnight': 281,\n",
       " 'sun': 282,\n",
       " 'beauti': 283,\n",
       " 'canal': 284,\n",
       " 'dasvidaniya': 285,\n",
       " 'till': 286,\n",
       " 'scout': 287,\n",
       " 'sg': 288,\n",
       " 'futur': 289,\n",
       " 'wlan': 290,\n",
       " 'pro': 291,\n",
       " 'confer': 292,\n",
       " 'asia': 293,\n",
       " 'chang': 294,\n",
       " 'lollipop': 295,\n",
       " 'üç≠': 296,\n",
       " 'nez': 297,\n",
       " 'agnezmo': 298,\n",
       " 'oley': 299,\n",
       " 'mama': 300,\n",
       " 'stand': 301,\n",
       " 'stronger': 302,\n",
       " 'god': 303,\n",
       " 'misti': 304,\n",
       " 'babi': 305,\n",
       " 'cute': 306,\n",
       " 'woohoo': 307,\n",
       " \"can't\": 308,\n",
       " 'sign': 309,\n",
       " 'yet': 310,\n",
       " 'still': 311,\n",
       " 'think': 312,\n",
       " 'mka': 313,\n",
       " 'liam': 314,\n",
       " 'access': 315,\n",
       " 'welcom': 316,\n",
       " 'stat': 317,\n",
       " 'arriv': 318,\n",
       " '1': 319,\n",
       " 'unfollow': 320,\n",
       " 'via': 321,\n",
       " 'surpris': 322,\n",
       " 'figur': 323,\n",
       " 'happybirthdayemilybett': 324,\n",
       " 'sweet': 325,\n",
       " 'talent': 326,\n",
       " '2': 327,\n",
       " 'plan': 328,\n",
       " 'drain': 329,\n",
       " 'gotta': 330,\n",
       " 'timezon': 331,\n",
       " 'parent': 332,\n",
       " 'proud': 333,\n",
       " 'least': 334,\n",
       " 'mayb': 335,\n",
       " 'sometim': 336,\n",
       " 'grade': 337,\n",
       " 'al': 338,\n",
       " 'grand': 339,\n",
       " 'manila_bro': 340,\n",
       " 'chosen': 341,\n",
       " 'let': 342,\n",
       " 'around': 343,\n",
       " '..': 344,\n",
       " 'side': 345,\n",
       " 'world': 346,\n",
       " 'eh': 347,\n",
       " 'take': 348,\n",
       " 'care': 349,\n",
       " 'final': 350,\n",
       " 'fuck': 351,\n",
       " 'weekend': 352,\n",
       " 'real': 353,\n",
       " 'x45': 354,\n",
       " 'join': 355,\n",
       " 'hushedcallwithfraydo': 356,\n",
       " 'gift': 357,\n",
       " 'yeahhh': 358,\n",
       " 'hushedpinwithsammi': 359,\n",
       " 'event': 360,\n",
       " 'might': 361,\n",
       " 'luv': 362,\n",
       " 'realli': 363,\n",
       " 'appreci': 364,\n",
       " 'share': 365,\n",
       " 'wow': 366,\n",
       " 'tom': 367,\n",
       " 'gym': 368,\n",
       " 'monday': 369,\n",
       " 'invit': 370,\n",
       " 'scope': 371,\n",
       " 'friend': 372,\n",
       " 'nude': 373,\n",
       " 'sleep': 374,\n",
       " 'birthday': 375,\n",
       " 'want': 376,\n",
       " 't-shirt': 377,\n",
       " 'cool': 378,\n",
       " 'haw': 379,\n",
       " 'phela': 380,\n",
       " 'mom': 381,\n",
       " 'obvious': 382,\n",
       " 'princ': 383,\n",
       " 'charm': 384,\n",
       " 'stage': 385,\n",
       " 'luck': 386,\n",
       " 'tyler': 387,\n",
       " 'hipster': 388,\n",
       " 'glass': 389,\n",
       " 'marti': 390,\n",
       " 'glad': 391,\n",
       " 'done': 392,\n",
       " 'afternoon': 393,\n",
       " 'read': 394,\n",
       " 'kahfi': 395,\n",
       " 'finish': 396,\n",
       " 'ohmyg': 397,\n",
       " 'yaya': 398,\n",
       " 'dub': 399,\n",
       " 'stalk': 400,\n",
       " 'ig': 401,\n",
       " 'gondooo': 402,\n",
       " 'moo': 403,\n",
       " 'tologooo': 404,\n",
       " 'becom': 405,\n",
       " 'detail': 406,\n",
       " 'zzz': 407,\n",
       " 'xx': 408,\n",
       " 'physiotherapi': 409,\n",
       " 'hashtag': 410,\n",
       " 'üí™': 411,\n",
       " 'monica': 412,\n",
       " 'miss': 413,\n",
       " 'sound': 414,\n",
       " 'morn': 415,\n",
       " \"that'\": 416,\n",
       " 'x43': 417,\n",
       " 'definit': 418,\n",
       " 'tri': 419,\n",
       " 'tonight': 420,\n",
       " 'took': 421,\n",
       " 'advic': 422,\n",
       " 'treviso': 423,\n",
       " 'concert': 424,\n",
       " 'citi': 425,\n",
       " 'countri': 426,\n",
       " \"i'll\": 427,\n",
       " 'start': 428,\n",
       " 'fine': 429,\n",
       " 'gorgeou': 430,\n",
       " 'xo': 431,\n",
       " 'oven': 432,\n",
       " 'roast': 433,\n",
       " 'garlic': 434,\n",
       " 'oliv': 435,\n",
       " 'oil': 436,\n",
       " 'dri': 437,\n",
       " 'tomato': 438,\n",
       " 'basil': 439,\n",
       " 'centuri': 440,\n",
       " 'tuna': 441,\n",
       " 'right': 442,\n",
       " 'back': 443,\n",
       " 'atchya': 444,\n",
       " 'even': 445,\n",
       " 'almost': 446,\n",
       " 'chanc': 447,\n",
       " 'cheer': 448,\n",
       " 'po': 449,\n",
       " 'ice': 450,\n",
       " 'cream': 451,\n",
       " 'agre': 452,\n",
       " '100': 453,\n",
       " 'heheheh': 454,\n",
       " 'that': 455,\n",
       " 'point': 456,\n",
       " 'stay': 457,\n",
       " 'home': 458,\n",
       " 'soon': 459,\n",
       " 'promis': 460,\n",
       " 'web': 461,\n",
       " 'whatsapp': 462,\n",
       " 'volta': 463,\n",
       " 'funcionar': 464,\n",
       " 'com': 465,\n",
       " 'iphon': 466,\n",
       " 'jailbroken': 467,\n",
       " 'later': 468,\n",
       " '34': 469,\n",
       " 'min': 470,\n",
       " 'leia': 471,\n",
       " 'appear': 472,\n",
       " 'hologram': 473,\n",
       " 'r2d2': 474,\n",
       " 'w': 475,\n",
       " 'messag': 476,\n",
       " 'obi': 477,\n",
       " 'wan': 478,\n",
       " 'sit': 479,\n",
       " 'luke': 480,\n",
       " 'inter': 481,\n",
       " '3': 482,\n",
       " 'ucl': 483,\n",
       " 'arsen': 484,\n",
       " 'small': 485,\n",
       " 'team': 486,\n",
       " 'pass': 487,\n",
       " 'üöÇ': 488,\n",
       " 'dewsburi': 489,\n",
       " 'railway': 490,\n",
       " 'station': 491,\n",
       " 'dew': 492,\n",
       " 'west': 493,\n",
       " 'yorkshir': 494,\n",
       " '430': 495,\n",
       " 'smh': 496,\n",
       " '9:25': 497,\n",
       " 'live': 498,\n",
       " 'strang': 499,\n",
       " 'imagin': 500,\n",
       " 'megan': 501,\n",
       " 'masaantoday': 502,\n",
       " 'a4': 503,\n",
       " 'shweta': 504,\n",
       " 'tripathi': 505,\n",
       " '5': 506,\n",
       " '20': 507,\n",
       " 'kurta': 508,\n",
       " 'half': 509,\n",
       " 'number': 510,\n",
       " 'wsalelov': 511,\n",
       " 'ah': 512,\n",
       " 'larri': 513,\n",
       " 'anyway': 514,\n",
       " 'kinda': 515,\n",
       " 'goood': 516,\n",
       " 'life': 517,\n",
       " 'enn': 518,\n",
       " 'could': 519,\n",
       " 'warmup': 520,\n",
       " '15th': 521,\n",
       " 'bath': 522,\n",
       " 'dum': 523,\n",
       " 'andar': 524,\n",
       " 'ram': 525,\n",
       " 'sampath': 526,\n",
       " 'sona': 527,\n",
       " 'mohapatra': 528,\n",
       " 'samantha': 529,\n",
       " 'edward': 530,\n",
       " 'mein': 531,\n",
       " 'tulan': 532,\n",
       " 'razi': 533,\n",
       " 'wah': 534,\n",
       " 'josh': 535,\n",
       " 'alway': 536,\n",
       " 'smile': 537,\n",
       " 'pictur': 538,\n",
       " '16.20': 539,\n",
       " 'giveitup': 540,\n",
       " 'given': 541,\n",
       " 'ga': 542,\n",
       " 'subsidi': 543,\n",
       " 'initi': 544,\n",
       " 'propos': 545,\n",
       " 'delight': 546,\n",
       " 'yesterday': 547,\n",
       " 'x42': 548,\n",
       " 'lmaoo': 549,\n",
       " 'song': 550,\n",
       " 'ever': 551,\n",
       " 'shall': 552,\n",
       " 'littl': 553,\n",
       " 'throwback': 554,\n",
       " 'outli': 555,\n",
       " 'island': 556,\n",
       " 'cheung': 557,\n",
       " 'chau': 558,\n",
       " 'mui': 559,\n",
       " 'wo': 560,\n",
       " 'total': 561,\n",
       " 'differ': 562,\n",
       " 'kfckitchentour': 563,\n",
       " 'kitchen': 564,\n",
       " 'clean': 565,\n",
       " \"i'm\": 566,\n",
       " 'cusp': 567,\n",
       " 'test': 568,\n",
       " 'water': 569,\n",
       " 'reward': 570,\n",
       " 'arummzz': 571,\n",
       " \"let'\": 572,\n",
       " 'drive': 573,\n",
       " 'travel': 574,\n",
       " 'yogyakarta': 575,\n",
       " 'jeep': 576,\n",
       " 'indonesia': 577,\n",
       " 'instamood': 578,\n",
       " 'wanna': 579,\n",
       " 'skype': 580,\n",
       " 'may': 581,\n",
       " 'nice': 582,\n",
       " 'friendli': 583,\n",
       " 'pretend': 584,\n",
       " 'film': 585,\n",
       " 'congratul': 586,\n",
       " 'winner': 587,\n",
       " 'cheesydelight': 588,\n",
       " 'contest': 589,\n",
       " 'address': 590,\n",
       " 'guy': 591,\n",
       " 'market': 592,\n",
       " '24/7': 593,\n",
       " '14': 594,\n",
       " 'hour': 595,\n",
       " 'leav': 596,\n",
       " 'without': 597,\n",
       " 'delay': 598,\n",
       " 'actual': 599,\n",
       " 'easi': 600,\n",
       " 'guess': 601,\n",
       " 'train': 602,\n",
       " 'wd': 603,\n",
       " 'shift': 604,\n",
       " 'engin': 605,\n",
       " 'etc': 606,\n",
       " 'sunburn': 607,\n",
       " 'peel': 608,\n",
       " 'blog': 609,\n",
       " 'huge': 610,\n",
       " 'warm': 611,\n",
       " '‚òÜ': 612,\n",
       " 'complet': 613,\n",
       " 'triangl': 614,\n",
       " 'northern': 615,\n",
       " 'ireland': 616,\n",
       " 'sight': 617,\n",
       " 'smthng': 618,\n",
       " 'fr': 619,\n",
       " 'hug': 620,\n",
       " 'xoxo': 621,\n",
       " 'uu': 622,\n",
       " 'jaann': 623,\n",
       " 'topnewfollow': 624,\n",
       " 'connect': 625,\n",
       " 'wonder': 626,\n",
       " 'made': 627,\n",
       " 'fluffi': 628,\n",
       " 'insid': 629,\n",
       " 'pirouett': 630,\n",
       " 'moos': 631,\n",
       " 'trip': 632,\n",
       " 'philli': 633,\n",
       " 'decemb': 634,\n",
       " \"i'd\": 635,\n",
       " 'dude': 636,\n",
       " 'x41': 637,\n",
       " 'question': 638,\n",
       " 'flaw': 639,\n",
       " 'pain': 640,\n",
       " 'negat': 641,\n",
       " 'strength': 642,\n",
       " 'went': 643,\n",
       " 'solo': 644,\n",
       " 'move': 645,\n",
       " 'fav': 646,\n",
       " 'nirvana': 647,\n",
       " 'smell': 648,\n",
       " 'teen': 649,\n",
       " 'spirit': 650,\n",
       " 'rip': 651,\n",
       " 'ami': 652,\n",
       " 'winehous': 653,\n",
       " 'coupl': 654,\n",
       " 'tomhiddleston': 655,\n",
       " 'elizabetholsen': 656,\n",
       " 'yaytheylookgreat': 657,\n",
       " 'goodnight': 658,\n",
       " 'vid': 659,\n",
       " 'wake': 660,\n",
       " 'gonna': 661,\n",
       " 'shoot': 662,\n",
       " 'itti': 663,\n",
       " 'bitti': 664,\n",
       " 'teeni': 665,\n",
       " 'bikini': 666,\n",
       " 'much': 667,\n",
       " '4th': 668,\n",
       " 'togeth': 669,\n",
       " 'end': 670,\n",
       " 'xfile': 671,\n",
       " 'content': 672,\n",
       " 'rain': 673,\n",
       " 'fabul': 674,\n",
       " 'fantast': 675,\n",
       " '‚ô°': 676,\n",
       " 'jb': 677,\n",
       " 'forev': 678,\n",
       " 'belieb': 679,\n",
       " 'nighti': 680,\n",
       " 'bug': 681,\n",
       " 'bite': 682,\n",
       " 'bracelet': 683,\n",
       " 'idea': 684,\n",
       " 'foundri': 685,\n",
       " 'game': 686,\n",
       " 'sens': 687,\n",
       " 'pic': 688,\n",
       " 'ef': 689,\n",
       " 'phone': 690,\n",
       " 'woot': 691,\n",
       " 'derek': 692,\n",
       " 'use': 693,\n",
       " 'parkshar': 694,\n",
       " 'gloucestershir': 695,\n",
       " 'aaaahhh': 696,\n",
       " 'man': 697,\n",
       " 'traffic': 698,\n",
       " 'stress': 699,\n",
       " 'reliev': 700,\n",
       " \"how'r\": 701,\n",
       " 'arbeloa': 702,\n",
       " 'turn': 703,\n",
       " '17': 704,\n",
       " 'omg': 705,\n",
       " 'say': 706,\n",
       " 'europ': 707,\n",
       " 'rise': 708,\n",
       " 'find': 709,\n",
       " 'hard': 710,\n",
       " 'believ': 711,\n",
       " 'uncount': 712,\n",
       " 'coz': 713,\n",
       " 'unlimit': 714,\n",
       " 'cours': 715,\n",
       " 'teamposit': 716,\n",
       " 'aldub': 717,\n",
       " '‚òï': 718,\n",
       " 'rita': 719,\n",
       " 'info': 720,\n",
       " \"we'd\": 721,\n",
       " 'way': 722,\n",
       " 'boy': 723,\n",
       " 'x40': 724,\n",
       " 'true': 725,\n",
       " 'sethi': 726,\n",
       " 'high': 727,\n",
       " 'exe': 728,\n",
       " 'skeem': 729,\n",
       " 'saam': 730,\n",
       " 'peopl': 731,\n",
       " 'polit': 732,\n",
       " 'izzat': 733,\n",
       " 'wese': 734,\n",
       " 'trust': 735,\n",
       " 'khawateen': 736,\n",
       " 'k': 737,\n",
       " 'sath': 738,\n",
       " 'mana': 739,\n",
       " 'kar': 740,\n",
       " 'deya': 741,\n",
       " 'sort': 742,\n",
       " 'smart': 743,\n",
       " 'hair': 744,\n",
       " 'tbh': 745,\n",
       " 'jacob': 746,\n",
       " 'g': 747,\n",
       " 'upgrad': 748,\n",
       " 'tee': 749,\n",
       " 'famili': 750,\n",
       " 'person': 751,\n",
       " 'two': 752,\n",
       " 'convers': 753,\n",
       " 'onlin': 754,\n",
       " 'mclaren': 755,\n",
       " 'fridayfeel': 756,\n",
       " 'tgif': 757,\n",
       " 'squar': 758,\n",
       " 'enix': 759,\n",
       " 'bissmillah': 760,\n",
       " 'ya': 761,\n",
       " 'allah': 762,\n",
       " \"we'r\": 763,\n",
       " 'socent': 764,\n",
       " 'startup': 765,\n",
       " 'drop': 766,\n",
       " 'your': 767,\n",
       " 'arnd': 768,\n",
       " 'town': 769,\n",
       " 'basic': 770,\n",
       " 'piss': 771,\n",
       " 'cup': 772,\n",
       " 'also': 773,\n",
       " 'terribl': 774,\n",
       " 'complic': 775,\n",
       " 'discuss': 776,\n",
       " 'snapchat': 777,\n",
       " 'lynettelow': 778,\n",
       " 'kikmenow': 779,\n",
       " 'snapm': 780,\n",
       " 'hot': 781,\n",
       " 'amazon': 782,\n",
       " 'kikmeguy': 783,\n",
       " 'defin': 784,\n",
       " 'grow': 785,\n",
       " 'sport': 786,\n",
       " 'rt': 787,\n",
       " 'rakyat': 788,\n",
       " 'write': 789,\n",
       " 'sinc': 790,\n",
       " 'mention': 791,\n",
       " 'fli': 792,\n",
       " 'fish': 793,\n",
       " 'promot': 794,\n",
       " 'post': 795,\n",
       " 'cyber': 796,\n",
       " 'ourdaughtersourprid': 797,\n",
       " 'mypapamyprid': 798,\n",
       " 'papa': 799,\n",
       " 'coach': 800,\n",
       " 'posit': 801,\n",
       " 'kha': 802,\n",
       " 'atleast': 803,\n",
       " 'x39': 804,\n",
       " 'mango': 805,\n",
       " \"lassi'\": 806,\n",
       " \"monty'\": 807,\n",
       " 'marvel': 808,\n",
       " 'though': 809,\n",
       " 'suspect': 810,\n",
       " 'meant': 811,\n",
       " '24': 812,\n",
       " 'hr': 813,\n",
       " 'touch': 814,\n",
       " 'kepler': 815,\n",
       " '452b': 816,\n",
       " 'chalna': 817,\n",
       " 'hai': 818,\n",
       " 'thankyou': 819,\n",
       " 'hazel': 820,\n",
       " 'food': 821,\n",
       " 'brooklyn': 822,\n",
       " 'pta': 823,\n",
       " 'awak': 824,\n",
       " 'okayi': 825,\n",
       " 'awww': 826,\n",
       " 'ha': 827,\n",
       " 'doc': 828,\n",
       " 'splendid': 829,\n",
       " 'spam': 830,\n",
       " 'folder': 831,\n",
       " 'amount': 832,\n",
       " 'nigeria': 833,\n",
       " 'claim': 834,\n",
       " 'rted': 835,\n",
       " 'leg': 836,\n",
       " 'hurt': 837,\n",
       " 'bad': 838,\n",
       " 'mine': 839,\n",
       " 'saturday': 840,\n",
       " 'thaaank': 841,\n",
       " 'puhon': 842,\n",
       " 'happinesss': 843,\n",
       " 'tnc': 844,\n",
       " 'prior': 845,\n",
       " 'notif': 846,\n",
       " 'fat': 847,\n",
       " 'co': 848,\n",
       " 'probabl': 849,\n",
       " 'ate': 850,\n",
       " 'yuna': 851,\n",
       " 'tamesid': 852,\n",
       " '¬¥': 853,\n",
       " 'googl': 854,\n",
       " 'account': 855,\n",
       " 'scouser': 856,\n",
       " 'everyth': 857,\n",
       " 'zoe': 858,\n",
       " 'mate': 859,\n",
       " 'liter': 860,\n",
       " \"they'r\": 861,\n",
       " 'samee': 862,\n",
       " 'edgar': 863,\n",
       " 'updat': 864,\n",
       " 'log': 865,\n",
       " 'bring': 866,\n",
       " 'abe': 867,\n",
       " 'meet': 868,\n",
       " 'x38': 869,\n",
       " 'sigh': 870,\n",
       " 'dreamili': 871,\n",
       " 'pout': 872,\n",
       " 'eye': 873,\n",
       " 'quacketyquack': 874,\n",
       " 'funni': 875,\n",
       " 'happen': 876,\n",
       " 'phil': 877,\n",
       " 'em': 878,\n",
       " 'del': 879,\n",
       " 'rodder': 880,\n",
       " 'els': 881,\n",
       " 'play': 882,\n",
       " 'newest': 883,\n",
       " 'gamejam': 884,\n",
       " 'irish': 885,\n",
       " 'literatur': 886,\n",
       " 'inaccess': 887,\n",
       " \"kareena'\": 888,\n",
       " 'fan': 889,\n",
       " 'brain': 890,\n",
       " 'dot': 891,\n",
       " 'braindot': 892,\n",
       " 'fair': 893,\n",
       " 'rush': 894,\n",
       " 'either': 895,\n",
       " 'brandi': 896,\n",
       " '18': 897,\n",
       " 'carniv': 898,\n",
       " 'men': 899,\n",
       " 'put': 900,\n",
       " 'mask': 901,\n",
       " 'xavier': 902,\n",
       " 'forneret': 903,\n",
       " 'jennif': 904,\n",
       " 'site': 905,\n",
       " 'free': 906,\n",
       " '50.000': 907,\n",
       " '8': 908,\n",
       " 'ball': 909,\n",
       " 'pool': 910,\n",
       " 'coin': 911,\n",
       " 'edit': 912,\n",
       " 'trish': 913,\n",
       " '‚ô•': 914,\n",
       " 'grate': 915,\n",
       " 'three': 916,\n",
       " 'comment': 917,\n",
       " 'wakeup': 918,\n",
       " 'besid': 919,\n",
       " 'dirti': 920,\n",
       " 'sex': 921,\n",
       " 'lmaooo': 922,\n",
       " 'üò§': 923,\n",
       " 'loui': 924,\n",
       " \"he'\": 925,\n",
       " 'throw': 926,\n",
       " 'caus': 927,\n",
       " 'inspir': 928,\n",
       " 'ff': 929,\n",
       " 'twoof': 930,\n",
       " 'gr8': 931,\n",
       " 'wkend': 932,\n",
       " 'kind': 933,\n",
       " 'exhaust': 934,\n",
       " 'word': 935,\n",
       " 'cheltenham': 936,\n",
       " 'area': 937,\n",
       " 'kale': 938,\n",
       " 'crisp': 939,\n",
       " 'ruin': 940,\n",
       " 'x37': 941,\n",
       " 'open': 942,\n",
       " 'worldwid': 943,\n",
       " 'outta': 944,\n",
       " 'sfvbeta': 945,\n",
       " 'vantast': 946,\n",
       " 'xcylin': 947,\n",
       " 'bundl': 948,\n",
       " 'show': 949,\n",
       " 'internet': 950,\n",
       " 'price': 951,\n",
       " 'realisticli': 952,\n",
       " 'pay': 953,\n",
       " 'net': 954,\n",
       " 'educ': 955,\n",
       " 'power': 956,\n",
       " 'weapon': 957,\n",
       " 'nelson': 958,\n",
       " 'mandela': 959,\n",
       " 'recent': 960,\n",
       " 'j': 961,\n",
       " 'chenab': 962,\n",
       " 'flow': 963,\n",
       " 'pakistan': 964,\n",
       " 'incredibleindia': 965,\n",
       " 'teenchoic': 966,\n",
       " 'choiceinternationalartist': 967,\n",
       " 'superjunior': 968,\n",
       " 'caught': 969,\n",
       " 'first': 970,\n",
       " 'salmon': 971,\n",
       " 'super-blend': 972,\n",
       " 'project': 973,\n",
       " 'youth@bipolaruk.org.uk': 974,\n",
       " 'awesom': 975,\n",
       " 'stream': 976,\n",
       " 'alma': 977,\n",
       " 'mater': 978,\n",
       " 'highschoolday': 979,\n",
       " 'clientvisit': 980,\n",
       " 'faith': 981,\n",
       " 'christian': 982,\n",
       " 'school': 983,\n",
       " 'lizaminnelli': 984,\n",
       " 'upcom': 985,\n",
       " 'uk': 986,\n",
       " 'üòÑ': 987,\n",
       " 'singl': 988,\n",
       " 'hill': 989,\n",
       " 'everi': 990,\n",
       " 'beat': 991,\n",
       " 'wrong': 992,\n",
       " 'readi': 993,\n",
       " 'natur': 994,\n",
       " 'pefumeri': 995,\n",
       " 'workshop': 996,\n",
       " 'neal': 997,\n",
       " 'yard': 998,\n",
       " 'covent': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273cdc2",
   "metadata": {},
   "source": [
    "## 1.3 Converting a tweet to a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ccb1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet - A string containing a tweet\n",
    "        vocab_dict - The words dictionary\n",
    "        unk_token - The special string for unknown tokens\n",
    "        verbose - Print info durign runtime\n",
    "    Output:\n",
    "        tensor_lst - A python list with\n",
    "        \n",
    "    '''\n",
    "    word_lst = process_tweet(tweet)\n",
    "    \n",
    "    if verbose:\n",
    "        print('List of words from processed tweet:')\n",
    "        print(word_lst)\n",
    "    \n",
    "    tensor_lst = []\n",
    "    \n",
    "    unk_ID = vocab_dict[unk_token]\n",
    "    \n",
    "    if verbose:\n",
    "        print('The unique integer ID for the unk_token is {}'.format(unk_ID))\n",
    "        \n",
    "    for word in word_lst:\n",
    "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
    "        tensor_lst.append(word_ID)\n",
    "        \n",
    "    return tensor_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205bd229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual tweet: @heyclaireee is back! thnx God!!! i'm so happy :)\n",
      "\n",
      "Tensor of tweet: [443, 2, 303, 566, 56, 9]\n"
     ]
    }
   ],
   "source": [
    "tmp_twt = val_pos[1]\n",
    "\n",
    "print('Actual tweet: {}'.format(tmp_twt))\n",
    "print('\\nTensor of tweet: {}'.format(tweet_to_tensor(tmp_twt, Vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d36be",
   "metadata": {},
   "source": [
    "## 1.4 Creating a Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2f6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_pos, data_neg, batch_size, vocab_dict, loop, shuffle=False):\n",
    "    '''\n",
    "    Input: \n",
    "        data_pos - Set of positive examples\n",
    "        data_neg - Set of negative examples\n",
    "        batch_size - number of samples per batch. Must be even\n",
    "        loop - True or False\n",
    "        vocab_dict - The words dictionary\n",
    "        shuffle - Shuffle the data order\n",
    "    Yield:\n",
    "        inputs - Subset of positive and negative examples\n",
    "        targets - The corresponding labels for the subset\n",
    "        example_weights - A numpy array specifying the importance of each example\n",
    "        \n",
    "    '''\n",
    "    # make sure the batch size is an even number\n",
    "    # to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "    \n",
    "    # Number of positive examples in each batch is half of the batch size\n",
    "    # same with number of negative examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "    \n",
    "    len_data_pos = len(data_pos)\n",
    "    len_data_neg = len(data_neg)\n",
    "    \n",
    "    pos_index_lines = list(range(len_data_pos))\n",
    "    neg_index_lines = list(range(len_data_neg))\n",
    "    \n",
    "    if shuffle:\n",
    "        rnd.shuffle(pos_index_lines)\n",
    "        rnd.shuffle(neg_index_lines)\n",
    "    \n",
    "    stop = False\n",
    "    \n",
    "    while not stop:\n",
    "        batch = []\n",
    "        \n",
    "        for i in range(n_to_take):\n",
    "            if pos_index >= len_data_pos:\n",
    "                if not loop:\n",
    "                    stop = True\n",
    "                    break\n",
    "                \n",
    "                pos_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    rnd.shuffle(pos_index_lines)\n",
    "                    \n",
    "            tweet = data_pos[pos_index_lines[pos_index]]\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            batch.append(tensor)\n",
    "            pos_index += 1\n",
    "        \n",
    "        for i in range(n_to_take):\n",
    "            if neg_index >= len_data_neg:\n",
    "                if not loop:\n",
    "                    stop = True\n",
    "                    break\n",
    "                    \n",
    "                neg_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    rnd.shuffle(neg_index_lines)\n",
    "                    \n",
    "            tweet = data_neg[neg_index_lines[neg_index]]\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            batch.append(tensor)\n",
    "            neg_index += 1\n",
    "            \n",
    "        if stop:\n",
    "            break;\n",
    "        \n",
    "        max_len = max([len(t) for t in batch])\n",
    "        \n",
    "        tensor_pad_lst = []\n",
    "        \n",
    "        for tensor in batch:\n",
    "            n_pad = max_len - len(tensor)\n",
    "            pad_lst = [0] * n_pad\n",
    "            tensor_pad = tensor + pad_lst\n",
    "            tensor_pad_lst.append(tensor_pad)\n",
    "        \n",
    "        inputs = np.array(tensor_pad_lst)\n",
    "        target_pos = [1] * n_to_take\n",
    "        target_neg = [0] * n_to_take\n",
    "        target_lst = target_pos + target_neg\n",
    "        targets = np.array(target_lst)\n",
    "        example_weights = np.ones_like(targets)\n",
    "        \n",
    "        yield inputs, targets, example_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212d6191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[2005 4450 3200    9    0    0    0    0    0    0    0]\n",
      " [4953  566 2000 1453 5173 3498  141 3498  130  458    9]\n",
      " [ 566 4848   92  353   45    9    0    0    0    0    0]\n",
      " [3760  109  136  582 2929 3968    0    0    0    0    0]\n",
      " [ 249 3760    0    0    0    0    0    0    0    0    0]\n",
      " [3820 7152 3760    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Targets: [1 1 1 0 0 0]\n",
      "\n",
      "Example Weights: [1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "rnd.seed(30)\n",
    "\n",
    "def train_generator(train_pos, train_neg, batch_size, vocab_dict, loop=True, shuffle=False):\n",
    "    return data_generator(train_pos, train_neg, batch_size, vocab_dict, loop, shuffle)\n",
    "\n",
    "inputs, targets, example_weights = next(train_generator(train_pos, train_neg, 6, Vocab, shuffle=True))\n",
    "\n",
    "print('Inputs: {}'.format(inputs))\n",
    "print('\\nTargets: {}'.format(targets))\n",
    "print('\\nExample Weights: {}'.format(example_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edc7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(val_pos, val_neg, batch_size, vocab_dict, loop=True, shuffle=False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, vocab_dict, loop, shuffle)\n",
    "\n",
    "def test_generator(val_pos, val_neg, batch_size, vocab_dict, loop=False, shuffle=False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, vocab_dict, loop, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd23a6",
   "metadata": {},
   "source": [
    "# 2. Defining Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf91a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        pass\n",
    "    \n",
    "    def init(self, input_signature, random_key):\n",
    "        self.init_weights_and_state(input_signature, random_key)\n",
    "        return self.weights\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695c4cd",
   "metadata": {},
   "source": [
    "## 2.1 ReLU Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ab4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    def forward(self, x):\n",
    "        activation = np.maximum(x, 0)\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7a9316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[-2 -1  0]\n",
      " [ 0  1  2]]\n",
      "Output of Relu:\n",
      "[[0 0 0]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[-2, -1, 0], [0, 1, 2]])\n",
    "\n",
    "relu_layer = Relu()\n",
    "\n",
    "print('Original data:')\n",
    "print(x)\n",
    "print('Output of Relu:')\n",
    "print(relu_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83427856",
   "metadata": {},
   "source": [
    "## 2.2 Dense Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c55af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, n_units, init_stdev=0.1):\n",
    "        self._n_units = n_units\n",
    "        self._init_stdev = init_stdev\n",
    "        \n",
    "    def forward(self, x):\n",
    "        dense = np.dot(x, self.weights)\n",
    "        return dense\n",
    "    \n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        input_shape = input_signature.shape\n",
    "        w = self._init_stdev * trax.fastmath.random.normal(key = random_key,\n",
    "                                                           shape = (input_shape[1], self._n_units),\n",
    "                                                           )\n",
    "        self.weights = w\n",
    "        \n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f93064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights are:\n",
      "[[-0.02837107  0.09368163 -0.10050073  0.14165013  0.10543301  0.09108127\n",
      "  -0.04265671  0.0986188  -0.05575324  0.0015325 ]\n",
      " [-0.2078568   0.05548371  0.09142365  0.05744596  0.07227863  0.01210618\n",
      "  -0.03237354  0.16234998  0.02450039 -0.13809781]\n",
      " [-0.06111237  0.01403725  0.08410043 -0.10943579 -0.1077502  -0.11396457\n",
      "  -0.0593338  -0.01557651 -0.03832145 -0.11144515]]\n"
     ]
    }
   ],
   "source": [
    "dense_layer = Dense(n_units=10)\n",
    "random_key = trax.fastmath.random.get_prng(seed=0)\n",
    "z = np.array([[2, 7, 25]])\n",
    "\n",
    "dense_layer.init(z, random_key)\n",
    "\n",
    "print('Weights are:\\n{}'.format(dense_layer.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c6c77b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward function output is: \n",
      "[[-3.0395489   0.9266805   2.5414748  -2.0504727  -1.9769386  -2.5822086\n",
      "  -1.7952733   0.94427466 -0.89803994 -3.7497485 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Forward function output is: \\n{}'.format(dense_layer(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00740414",
   "metadata": {},
   "source": [
    "## 2.3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a168056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding_3_2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd.seed(31)\n",
    "exp_embed = tl.Embedding(d_feature=2, vocab_size=3)\n",
    "display(exp_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a465651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[-0.09254155,  1.1765094 ],\n",
       "              [ 1.0511576 ,  0.7154667 ],\n",
       "              [ 0.7439485 , -0.81590366]], dtype=float32),\n",
       " ())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 0, 2]])\n",
    "\n",
    "exp_embed.init(trax.shapes.signature(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c552da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[-0.09254155,  1.1765094 ],\n",
       "              [ 1.0511576 ,  0.7154667 ],\n",
       "              [ 0.7439485 , -0.81590366]],\n",
       "\n",
       "             [[ 0.7439485 , -0.81590366],\n",
       "              [-0.09254155,  1.1765094 ],\n",
       "              [ 0.7439485 , -0.81590366]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_embed_arr = exp_embed(arr)\n",
    "exp_embed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11348cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_embed_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb55a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean along axis 0 creates a vector whose length equals the number of features in a word embedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([3., 4.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean along axis 1 creates a vector whose length equals the number of words in a sentence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.5, 3.5, 5.5], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_embeded = np.array([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "\n",
    "# take the mean along axis 0\n",
    "print(\"The mean along axis 0 creates a vector whose length equals the number of features in a word embedding\")\n",
    "display(np.mean(tmp_embeded,axis=0))\n",
    "\n",
    "print(\"The mean along axis 1 creates a vector whose length equals the number of words in a sentence\")\n",
    "display(np.mean(tmp_embeded,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c1ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(vocab_size=9088, embedding_dim=256, output_dim=2, mode='train'):\n",
    "    \n",
    "    embed_layer = tl.Embedding(vocab_size=vocab_size, d_feature=embedding_dim)\n",
    "    \n",
    "    mean_layer = tl.Mean(axis=1)\n",
    "    \n",
    "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
    "    \n",
    "    log_softmax_layer = tl.LogSoftmax()\n",
    "    \n",
    "    model = tl.Serial(embed_layer,\n",
    "                      mean_layer,\n",
    "                      dense_output_layer,\n",
    "                      log_softmax_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e81bb0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Embedding_9088_256\n",
       "  Mean\n",
       "  Dense_2\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_model = classifier(vocab_size=len(Vocab))\n",
    "\n",
    "exp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890eeba",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3f91a",
   "metadata": {},
   "source": [
    "## 3.1 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da516af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "def get_train_eval_tasks(train_pos, train_neg, val_pos, val_neg, vocab_dict, loop, batch_size=16):\n",
    "    \n",
    "    rnd.seed(271)\n",
    "    \n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data = train_generator(train_pos, train_neg, batch_size, vocab_dict, loop, shuffle=True),\n",
    "        loss_layer = tl.WeightedCategoryCrossEntropy(),\n",
    "        optimizer = trax.optimizers.Adam(0.01),\n",
    "        n_steps_per_checkpoint=10)\n",
    "    \n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data = val_generator(val_pos, val_neg, batch_size, vocab_dict, loop, shuffle=True),\n",
    "        metrics = [tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()])\n",
    "    \n",
    "    return train_task, eval_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571468cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task, eval_task = get_train_eval_tasks(train_pos, train_neg, val_pos, val_neg, \n",
    "                                             Vocab, loop=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b2bcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80a2c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/\n"
     ]
    }
   ],
   "source": [
    "dir_path = './model/'\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(dir_path)\n",
    "except OSError as e:\n",
    "    pass\n",
    "\n",
    "output_dir = './model/'\n",
    "output_dir_expand = os.path.expanduser(output_dir)\n",
    "print(output_dir_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "608ef1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
    "    '''\n",
    "    Input: \n",
    "        classifier - the model you are building\n",
    "        train_task - Training task\n",
    "        eval_task - Evaluation task. Received as a list.\n",
    "        n_steps - the evaluation steps\n",
    "        output_dir - folder to save your files\n",
    "    Output:\n",
    "        trainer -  trax trainer\n",
    "    '''\n",
    "    rnd.seed(31)\n",
    "    \n",
    "    training_loop = training.Loop(classifier,\n",
    "                                  train_task,\n",
    "                                  eval_tasks = eval_task,\n",
    "                                  output_dir = output_dir,\n",
    "                                  random_seed=31\n",
    "                                 )\n",
    "    \n",
    "    training_loop.run(n_steps = n_steps)\n",
    "    \n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b7c98e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2327042\n",
      "Step      1: Ran 1 train steps in 0.86 secs\n",
      "Step      1: train WeightedCategoryCrossEntropy |  0.69147205\n",
      "Step      1: eval  WeightedCategoryCrossEntropy |  0.69827205\n",
      "Step      1: eval      WeightedCategoryAccuracy |  0.43750000\n",
      "\n",
      "Step     10: Ran 9 train steps in 3.73 secs\n",
      "Step     10: train WeightedCategoryCrossEntropy |  0.64355624\n",
      "Step     10: eval  WeightedCategoryCrossEntropy |  0.53490156\n",
      "Step     10: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     20: Ran 10 train steps in 1.46 secs\n",
      "Step     20: train WeightedCategoryCrossEntropy |  0.45552301\n",
      "Step     20: eval  WeightedCategoryCrossEntropy |  0.33445308\n",
      "Step     20: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     30: Ran 10 train steps in 1.17 secs\n",
      "Step     30: train WeightedCategoryCrossEntropy |  0.24172144\n",
      "Step     30: eval  WeightedCategoryCrossEntropy |  0.15988171\n",
      "Step     30: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     40: Ran 10 train steps in 0.73 secs\n",
      "Step     40: train WeightedCategoryCrossEntropy |  0.13319710\n",
      "Step     40: eval  WeightedCategoryCrossEntropy |  0.06211402\n",
      "Step     40: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     50: Ran 10 train steps in 1.30 secs\n",
      "Step     50: train WeightedCategoryCrossEntropy |  0.08442788\n",
      "Step     50: eval  WeightedCategoryCrossEntropy |  0.05709711\n",
      "Step     50: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     60: Ran 10 train steps in 0.79 secs\n",
      "Step     60: train WeightedCategoryCrossEntropy |  0.04599970\n",
      "Step     60: eval  WeightedCategoryCrossEntropy |  0.02517334\n",
      "Step     60: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     70: Ran 10 train steps in 0.78 secs\n",
      "Step     70: train WeightedCategoryCrossEntropy |  0.04002561\n",
      "Step     70: eval  WeightedCategoryCrossEntropy |  0.00245687\n",
      "Step     70: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     80: Ran 10 train steps in 0.80 secs\n",
      "Step     80: train WeightedCategoryCrossEntropy |  0.01901614\n",
      "Step     80: eval  WeightedCategoryCrossEntropy |  0.00494147\n",
      "Step     80: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step     90: Ran 10 train steps in 0.73 secs\n",
      "Step     90: train WeightedCategoryCrossEntropy |  0.04117220\n",
      "Step     90: eval  WeightedCategoryCrossEntropy |  0.00762666\n",
      "Step     90: eval      WeightedCategoryAccuracy |  1.00000000\n",
      "\n",
      "Step    100: Ran 10 train steps in 1.13 secs\n",
      "Step    100: train WeightedCategoryCrossEntropy |  0.01523942\n",
      "Step    100: eval  WeightedCategoryCrossEntropy |  0.09424848\n",
      "Step    100: eval      WeightedCategoryAccuracy |  0.93750000\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(model, train_task, [eval_task], 100, output_dir_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5c2f5",
   "metadata": {},
   "source": [
    "## 3.2 Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b54a8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_generator = train_generator(train_pos, train_neg, 16, Vocab, loop=True, shuffle = False)\n",
    "\n",
    "tmp_batch = next(tmp_train_generator)\n",
    "\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f86fc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[   3,    4,    5,    6,    7,    8,    9,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [  10,   11,   12,   13,   14,   15,   16,   17,   18,   19,\n",
       "                 20,    9,   21,   22,    0],\n",
       "              [  23,   24,   25,    9,   26,   27,   28,   29,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [  30,    9,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [  31,   32,   33,   34,   35,   36,   37,   38,   39,   40,\n",
       "                 41,   42,    9,   43,   44],\n",
       "              [  45,   46,    9,   47,    0,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [  48,   49,   50,   51,   52,   53,   54,   55,   56,   57,\n",
       "                 58,    9,    0,    0,    0],\n",
       "              [  59,   60,   61,   62,   63,   64,    9,   65,   66,   67,\n",
       "                 68,   69,   70,   71,    0],\n",
       "              [5736, 2900, 3760,    0,    0,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [ 857,  255, 3651, 5737,  306, 4457,  566, 1229, 2766,  327,\n",
       "               1201, 3760,    0,    0,    0],\n",
       "              [1035, 5738, 1428, 2428, 3760,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [1804, 1013, 1405,   15, 5739, 3760, 3760, 2099,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [1233,  428,  225,    8,  130, 3760,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [ 221,  303,  305, 3982, 3760,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [ 228,  537, 3760,    0,    0,    0,    0,    0,    0,    0,\n",
       "                  0,    0,    0,    0,    0],\n",
       "              [ 130, 5740, 5741, 1559, 1869, 1013,  864, 5742, 3760,    0,\n",
       "                  0,    0,    0,    0,    0]], dtype=int32),\n",
       " DeviceArray([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " DeviceArray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a614c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch is a tuple of length 3 because position 0 contains the tweets, and position 1 contains the targets.\n",
      "\n",
      "The shape of the tweet tensors is (16, 15) (num of examples, length of tweet tensors)\n",
      "\n",
      "The shape of the labels is (16,), which is the batch size.\n",
      "\n",
      "The shape of the example_weights is (16,), which is the same as inputs/targets size.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.\") \n",
    "print(f\"\\nThe shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)\")\n",
    "print(f\"\\nThe shape of the labels is {tmp_targets.shape}, which is the batch size.\")\n",
    "print(f\"\\nThe shape of the example_weights is {tmp_example_weights.shape}, which is the same as inputs/targets size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c22895e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-9.45541382e+00, -7.82012939e-05],\n",
       "             [-7.91714096e+00, -3.64542007e-04],\n",
       "             [-1.08034649e+01, -2.05039978e-05],\n",
       "             [-7.28871250e+00, -6.83546066e-04],\n",
       "             [-5.47317123e+00, -4.20665741e-03],\n",
       "             [-8.18597984e+00, -2.78472900e-04],\n",
       "             [-9.05854225e+00, -1.16348267e-04],\n",
       "             [-7.35542679e+00, -6.39438629e-04],\n",
       "             [-2.35319138e-03, -6.05316162e+00],\n",
       "             [-2.82764435e-04, -8.17061806e+00],\n",
       "             [-1.15513802e-03, -6.76408100e+00],\n",
       "             [-1.90734863e-06, -1.31217785e+01],\n",
       "             [-2.30731964e-02, -3.78059936e+00],\n",
       "             [-5.58590889e-03, -5.19031191e+00],\n",
       "             [-2.30097771e-03, -6.07555199e+00],\n",
       "             [-1.73568726e-04, -8.65911102e+00]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "\n",
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85af6729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg log prob -9.4554\tPos log prob -0.0001\t is positive? True\t actual 1\n",
      "Neg log prob -7.9171\tPos log prob -0.0004\t is positive? True\t actual 1\n",
      "Neg log prob -10.8035\tPos log prob -0.0000\t is positive? True\t actual 1\n",
      "Neg log prob -7.2887\tPos log prob -0.0007\t is positive? True\t actual 1\n",
      "Neg log prob -5.4732\tPos log prob -0.0042\t is positive? True\t actual 1\n",
      "Neg log prob -8.1860\tPos log prob -0.0003\t is positive? True\t actual 1\n",
      "Neg log prob -9.0585\tPos log prob -0.0001\t is positive? True\t actual 1\n",
      "Neg log prob -7.3554\tPos log prob -0.0006\t is positive? True\t actual 1\n",
      "Neg log prob -0.0024\tPos log prob -6.0532\t is positive? False\t actual 0\n",
      "Neg log prob -0.0003\tPos log prob -8.1706\t is positive? False\t actual 0\n",
      "Neg log prob -0.0012\tPos log prob -6.7641\t is positive? False\t actual 0\n",
      "Neg log prob -0.0000\tPos log prob -13.1218\t is positive? False\t actual 0\n",
      "Neg log prob -0.0231\tPos log prob -3.7806\t is positive? False\t actual 0\n",
      "Neg log prob -0.0056\tPos log prob -5.1903\t is positive? False\t actual 0\n",
      "Neg log prob -0.0023\tPos log prob -6.0756\t is positive? False\t actual 0\n",
      "Neg log prob -0.0002\tPos log prob -8.6591\t is positive? False\t actual 0\n"
     ]
    }
   ],
   "source": [
    "tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]\n",
    "\n",
    "for i, p in enumerate(tmp_is_positive):\n",
    "    print(f\"Neg log prob {tmp_pred[i,0]:.4f}\\tPos log prob {tmp_pred[i,1]:.4f}\\t is positive? {p}\\t actual {tmp_targets[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfb3288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             False, False, False, False, False, False, False, False],            dtype=bool)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tmp_is_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b08931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_is_positive_int = tmp_is_positive.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "984f2331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tmp_is_positive_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1f2220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_is_positive_float = tmp_is_positive.astype(np.float32)\n",
    "display(tmp_is_positive_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828beae4",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e17a6",
   "metadata": {},
   "source": [
    "## 4.1 Computing the Accuracy on a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d330b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, y, y_weights):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        preds: a tensor of shape (dim_batch, output_dim) \n",
    "        y: a tensor of shape (dim_batch,) with the true labels\n",
    "        y_weights: a n.ndarray with the a weight for each example\n",
    "    Output: \n",
    "        accuracy: a float between 0-1 \n",
    "        weighted_num_correct (np.float32): Sum of the weighted correct predictions\n",
    "        sum_weights (np.float32): Sum of the weights\n",
    "    \"\"\"\n",
    "    \n",
    "    is_pos = preds[:, 1] > preds[:, 0]\n",
    "    is_pos_int = is_pos.astype(np.int32)\n",
    "    \n",
    "    correct = is_pos_int == y\n",
    "    \n",
    "    sum_weights = np.sum(y_weights)\n",
    "    \n",
    "    correct_float = correct.astype(np.float32)\n",
    "    \n",
    "    weighted_correct_float = correct_float * y_weights\n",
    "    weighted_num_correct = np.sum(weighted_correct_float)\n",
    "    \n",
    "    accuracy = weighted_num_correct / sum_weights\n",
    "    \n",
    "    return accuracy, weighted_num_correct, sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a347e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_eval_generator = val_generator(val_pos, val_neg, 64, Vocab, loop=True, shuffle=True)\n",
    "\n",
    "tmp_batch = next(tmp_eval_generator)\n",
    "\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
    "\n",
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "\n",
    "tmp_acc, tmp_num_correct, tmp_num_predictions = compute_accuracy(preds=tmp_pred, \n",
    "                                                                 y=tmp_targets, \n",
    "                                                                 y_weights=tmp_example_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a24c0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray of model in single training batch: 100.0%\n",
      "\n",
      "Weighted number of correct predictions: 64.0\n",
      "\n",
      "Weighted number of total observations: 64\n"
     ]
    }
   ],
   "source": [
    "print('Accuray of model in single training batch: {}%'.format(tmp_acc * 100))\n",
    "print('\\nWeighted number of correct predictions: {}'.format(tmp_num_correct))\n",
    "print('\\nWeighted number of total observations: {}'.format(tmp_num_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2b553",
   "metadata": {},
   "source": [
    "## 4.2 Testing on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "841f94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(generator, model, compute_accuracy=compute_accuracy):\n",
    "    '''\n",
    "    Input: \n",
    "        generator: an iterator instance that provides batches of inputs and targets\n",
    "        model: a model instance \n",
    "    Output: \n",
    "        accuracy: float corresponding to the accuracy\n",
    "    '''\n",
    "    accuracy = 0.\n",
    "    total_num_correct = 0\n",
    "    total_num_pred = 0\n",
    "    \n",
    "    for batch in generator:\n",
    "        inputs = batch[0]\n",
    "        targets = batch[1]\n",
    "        example_weight = batch[2]\n",
    "        \n",
    "        pred = model(inputs)\n",
    "        \n",
    "        batch_acc, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight)\n",
    "        \n",
    "        total_num_correct += batch_num_correct\n",
    "        total_num_pred += batch_num_pred\n",
    "        \n",
    "    accuracy = total_num_correct / total_num_pred\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb71fa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model in validation set: 0.9955\n"
     ]
    }
   ],
   "source": [
    "model = training_loop.eval_model\n",
    "accuracy = test_model(test_generator(val_pos, val_neg, 16, Vocab, loop=False, shuffle=False), model)\n",
    "\n",
    "print('The accuracy of model in validation set: {:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99c561",
   "metadata": {},
   "source": [
    "# 5. Testing with custome Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ec1bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    \n",
    "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
    "    inputs = inputs[None, :]\n",
    "    \n",
    "    preds_probs = model(inputs)\n",
    "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
    "    \n",
    "    sentiment = 'negative'\n",
    "    \n",
    "    if preds == 1:\n",
    "        sentiment = 'positive'\n",
    "        \n",
    "    return preds, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18591ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      "It's such a nice day, I think I'll be taking Sid to Ramsgate for lunch and then to the beach maybe.\n",
      "\n",
      "The sentence above is positive\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's such a nice day, I think I'll be taking Sid to Ramsgate for lunch and then to the beach maybe.\"\n",
    "\n",
    "print('Sentence: \\n{}'.format(sentence))\n",
    "\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "\n",
    "print('\\nThe sentence above is {}'.format(tmp_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c999c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \n",
      "It's such a worst day!!! I didn't like this day!\n",
      "\n",
      "The sentence above is negative\n"
     ]
    }
   ],
   "source": [
    "sentence = \"It's such a worst day!!! I didn't like this day!\"\n",
    "\n",
    "print('Sentence: \\n{}'.format(sentence))\n",
    "\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "\n",
    "print('\\nThe sentence above is {}'.format(tmp_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07740720",
   "metadata": {},
   "source": [
    "# 6. Words Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa41ae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9088, 256)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.weights[0]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3c644af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "embed_reduced = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf202f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = ['worst', 'bad', 'hurt', 'sad', 'hate']\n",
    "pos_words = ['best', 'good', 'nice', 'better', 'love']\n",
    "\n",
    "pos_n = [Vocab[w] for w in pos_words]\n",
    "neg_n = [Vocab[w] for w in neg_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46a193b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(embed_reduced[neg_n][:, 0], embed_reduced[neg_n][:, 1], color='r')\n",
    "for i, t in enumerate(neg_words):\n",
    "    plt.annotate(t, (embed_reduced[neg_n][i, 0], embed_reduced[neg_n][i, 1]))\n",
    "    \n",
    "plt.scatter(embed_reduced[pos_n][:, 0], embed_reduced[pos_n][:, 1])\n",
    "for i, t in enumerate(pos_words):\n",
    "    plt.annotate(t, (embed_reduced[pos_n][i, 0], embed_reduced[pos_n][i, 1]))\n",
    "\n",
    "plt.title('Words Embeddings in 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76da28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde688c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
